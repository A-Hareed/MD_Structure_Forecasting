{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import csv\n",
    "# from tensorflow.keras.layers import \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.version.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  , 36.94, 18.89, ..., 12.85, 33.87, 28.32],\n",
       "       [ 2.  , 37.85, 19.26, ..., 12.46, 29.87, 29.89],\n",
       "       [ 3.  , 36.41, 20.57, ..., 12.2 , 31.86, 29.85],\n",
       "       [ 4.  , 38.92, 19.58, ..., 14.17, 33.45, 28.3 ],\n",
       "       [ 5.  , 37.3 , 19.89, ..., 13.24, 32.89, 27.64]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coordinates_array = np.load('extracted_pdb_trajectory.npy')\n",
    "Coordinates_array = Coordinates_array.astype(float)\n",
    "Coordinates_array[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    2.0\n",
      "2    3.0\n",
      "3    4.0\n",
      "4    5.0\n",
      "Name: 0, dtype: float64\n",
      "     1      2      3      4      5      6      7      8      9      10   ...  \\\n",
      "0  36.94  18.89  22.61  36.54  19.60  22.01  37.79  19.17  23.07  37.15  ...   \n",
      "1  37.85  19.26  23.75  37.79  19.95  23.00  38.43  19.60  24.50  38.23  ...   \n",
      "2  36.41  20.57  21.10  35.96  20.64  20.20  36.99  21.39  21.24  37.08  ...   \n",
      "3  38.92  19.58  23.01  39.34  20.09  22.25  38.81  20.32  23.70  39.59  ...   \n",
      "4  37.30  19.89  24.43  37.90  20.66  24.18  36.63  20.27  25.09  37.94  ...   \n",
      "\n",
      "     510    511    512    513    514    515    516    517    518    519  \n",
      "0  27.25  12.55  32.67  28.49  12.41  32.12  29.63  12.85  33.87  28.32  \n",
      "1  28.13  12.70  28.70  29.47  12.80  27.72  30.22  12.46  29.87  29.89  \n",
      "2  31.67  12.52  30.73  30.42  13.32  30.69  31.38  12.20  31.86  29.85  \n",
      "3  29.00  15.11  32.68  28.54  16.12  32.88  29.23  14.17  33.45  28.30  \n",
      "4  29.30  13.76  32.09  28.46  14.10  32.55  29.58  13.24  32.89  27.64  \n",
      "\n",
      "[5 rows x 519 columns]\n"
     ]
    }
   ],
   "source": [
    "df_coo = pd.DataFrame(Coordinates_array)\n",
    "df_coo_time = df_coo[0]\n",
    "\n",
    "df_coo_only = df_coo.iloc[:,1:]\n",
    "print(df_coo_time.head())\n",
    "print(df_coo_only.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(519,)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_coo = df_coo_only.to_numpy()\n",
    "cleaned_coo[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.745102  , 0.38153908, 0.45649102, ..., 0.25970089, 0.68314834,\n",
       "        0.57226602],\n",
       "       [0.76348212, 0.38901232, 0.47950737, ..., 0.25181892, 0.6024218 ,\n",
       "        0.60400243],\n",
       "       [0.73439709, 0.41547162, 0.42600444, ..., 0.24656427, 0.64258325,\n",
       "        0.60319385],\n",
       "       ...,\n",
       "       [0.12401535, 0.32862048, 0.70866142, ..., 0.05618432, 0.3493441 ,\n",
       "        0.81443299],\n",
       "       [0.15229247, 0.31872349, 0.71269937, ..., 0.09660469, 0.37315843,\n",
       "        0.82029513],\n",
       "       [0.14865684, 0.36356292, 0.72057339, ..., 0.09417947, 0.40262361,\n",
       "        0.80068729]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Coordinates_array_scalled = scaler.fit_transform(Coordinates_array)\n",
    "Coordinates_array_scalled = scaler.fit_transform(cleaned_coo)\n",
    "\n",
    "Coordinates_array_scalled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4995, 519)\n",
      "(5, 519)\n"
     ]
    }
   ],
   "source": [
    "Coordinates_array_scalled_test = Coordinates_array_scalled[:5]\n",
    "Coordinates_array_scalled_train = Coordinates_array_scalled[5:]\n",
    "print(Coordinates_array_scalled_train.shape)\n",
    "print(Coordinates_array_scalled_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(519,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coordinates_array_scalled_test[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_input = keras.Input((520,), name='Alanine')\n",
    "x1 = keras.layers.Dense(260, activation='relu',name='x1')(encoder_input)\n",
    "x2 = keras.layers.Dense(130, activation='relu', name='x2')(x1)\n",
    "x3 = keras.layers.Dense(65, activation='relu', name='x3')(x2)\n",
    "# encoder_output = keras.layers.Dense(32, activation='relu', name='encoder_output')(x3)\n",
    "\n",
    "\n",
    "encoder = keras.Model(encoder_input, x3, name='Encoder')\n",
    "\n",
    "\n",
    "# decoder_layer1 = keras.layers.Dense(65,activation='relu',name='decoder_layer_1')(encoder_output)\n",
    "d1 = keras.layers.Dense(130, activation='relu', name='d1')(x3)              #(decoder_layer1)\n",
    "d2 = keras.layers.Dense(260, activation='relu', name='d2')(d1)              # (d1)\n",
    "# d3 = keras.layers.Dense(98, activation='relu', name='d3')(d2)\n",
    "decoder_output = keras.layers.Dense(520, activation='relu', name='decoder_output')(d2)\n",
    "\n",
    "autoencoder = keras.Model(encoder_input,decoder_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leakyRelu = keras.layers.LeakyReLU(alpha=0.3)\n",
    "\n",
    "encoder_input_lr = keras.Input((520,), name='PolyAlanine_leaky_relu')\n",
    "x1_lr = keras.layers.Dense(260, activation=leakyRelu,name='x1_lr')(encoder_input_lr)\n",
    "x2_lr = keras.layers.Dense(130, activation=leakyRelu, name='x2_lr')(x1_lr)\n",
    "x3_lr = keras.layers.Dense(65, activation=leakyRelu, name='x3_lr')(x2_lr)\n",
    "encoder_output_lr = keras.layers.Dense(32, activation=leakyRelu, name='encoder_output_lr')(x3_lr)\n",
    "\n",
    "\n",
    "encoder_lr = keras.Model(encoder_input_lr, encoder_output_lr, name='Encoder_lr')\n",
    "\n",
    "\n",
    "decoder_layer1_lr = keras.layers.Dense(65,activation=leakyRelu,name='decoder_layer_1_lr')(encoder_output_lr)\n",
    "d1_lr = keras.layers.Dense(130, activation=leakyRelu, name='d1_lr')(decoder_layer1_lr)\n",
    "d2_lr = keras.layers.Dense(260, activation=leakyRelu, name='d2_lr')(d1_lr)              # (d1)\n",
    "# d3 = keras.layers.Dense(98, activation='relu', name='d3')(d2)~=1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "autoencoder.compile(optimizer=opt, loss='mse')\n",
    "# autoencoder_lr.compile(optimizer=opt, loss='mse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train AutoEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(Coordinates_array_scalled_train,Coordinates_array_scalled_train,epochs=7,batch_size=20,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "~=1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_encoded = encoder.predict(Coordinates_array_scalled_test[0].reshape((-1,520)))\n",
    "example_AE = autoencoder.predict(Coordinates_array_scalled_test[0].reshape((-1,520)))\n",
    "example_AE_lr = autoencoder_lr.predict(Coordinates_array_scalled_test[0].reshape((-1,520)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_encoded = scaler.inverse_transform(example_encoded)\n",
    "example_AE = scaler.inverse_transform(example_AE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_AE_lr = scaler.inverse_transform(example_AE_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_AE_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = 0\n",
    "row_data = []\n",
    "predicted_data = []\n",
    "row_count = 0\n",
    "\n",
    "for i in list(example_AE_lr[0])[1:]:\n",
    "    # print(dat)\n",
    "    # print(stop)\n",
    "\n",
    "    row_data.append(i)\n",
    "    if row_count == 2:\n",
    "        predicted_data.append(row_data)\n",
    "        row_data = []\n",
    "        row_count = 0\n",
    "        continue\n",
    "    row_count += 1\n",
    "    stop += 1\n",
    "print(len(predicted_data))\n",
    "print(predicted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = 0\n",
    "row_data = []\n",
    "actual_data = []\n",
    "row_count = 0\n",
    "\n",
    "for i in list(Coordinates_array[0])[1:]:\n",
    "    # print(dat)\n",
    "    # print(stop)\n",
    "    row_data.append(i)\n",
    "    if row_count == 2:\n",
    "        actual_data.append(row_data)\n",
    "        row_data = []\n",
    "        row_count = 0\n",
    "        continue\n",
    "    row_count += 1\n",
    "    \n",
    "print(len(actual_data))\n",
    "print(actual_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(Coordinates_array_scalled_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_predicted = pd.DataFrame(predicted_data, columns=['X', 'Y', 'Z'])\n",
    "\n",
    "graph_actual = pd.DataFrame(actual_data, columns=['X', 'Y', 'Z'])\n",
    "graph_actual.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df = pd.DataFrame(full_data, columns=['X', 'Y', 'Z'])\n",
    "graph_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking how the Autoencoder preformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(graph_actual['X'], graph_actual['Y'], graph_actual['Z'])\n",
    "ax.plot3D(graph_predicted['X'], graph_predicted['Y'], graph_predicted['Z'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(graph_actual['X'], graph_actual['Y'], graph_actual['Z'])\n",
    "ax.scatter3D(graph_predicted['X'], graph_predicted['Y'], graph_predicted['Z'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph_predicted.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph_actual.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(graph_predicted.iloc[172])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreate the PDB file with updated Coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB = 'example_pdb.pdb'\n",
    "\n",
    "\n",
    "\n",
    "with open(PDB, newline='') as f:\n",
    "    pdb_file = csv.reader(f, delimiter='\\t')\n",
    "    temp_list = []\n",
    "# pdb_file[:6]\n",
    "# print(len(pdb_file))\n",
    "    row = []\n",
    "    full_data = []\n",
    "    counter = 0\n",
    "    pdb_output = ''\n",
    "    for line in pdb_file:\n",
    "\n",
    "        \n",
    "        if 'ATOM' not in line[0]:\n",
    "            pdb_output += ''.join(line) + '\\n'\n",
    "        elif 'ATOM' in line[0]:\n",
    "            line = line[0].split()\n",
    "            predicted_coordinates = list(graph_predicted.iloc[counter])\n",
    "            predicted_coordinates = [str(i) for i in predicted_coordinates]\n",
    "            # line = [i for i in line if i != '']\n",
    "            line = line[:6] + predicted_coordinates + line[10:]\n",
    "            line = '\\t'.join(line)\n",
    "            print(line)\n",
    "            pdb_output += line + '\\n'\n",
    "            print(counter)\n",
    "            counter +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predicted_polyA.pdb','w') as f:\n",
    "    f.write(pdb_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "leakyRelu = keras.layers.LeakyReLU(alpha=0.3)\n",
    "\n",
    "encoder_input_lr = keras.Input((519,), name='PolyAlanine_leaky_relu')\n",
    "x1_lr = keras.layers.Dense(300, activation=leakyRelu, name='x1_lr',kernel_initializer='normal')(encoder_input_lr)\n",
    "x2_lr = keras.layers.Dense(160, activation=leakyRelu, name='x2_lr',kernel_initializer='normal')(x1_lr)\n",
    "x3_lr = keras.layers.Dense(65, activation=leakyRelu, name='x3_lr',kernel_initializer='normal')(x2_lr)\n",
    "x4_lr = keras.layers.Dense(32, activation=leakyRelu, name='x4_lr',kernel_initializer='normal')(x3_lr)\n",
    "x5_lr = keras.layers.Dense(8, activation=leakyRelu, name='x5_lr',kernel_initializer='normal')(x4_lr)\n",
    "encoder_output_lr = keras.layers.Dense(2, activation=leakyRelu, name='encoder_output_lr',kernel_initializer='normal')(x5_lr)\n",
    "\n",
    "\n",
    "encoder_lr = keras.Model(encoder_input_lr, encoder_output_lr, name='Encoder_lr')\n",
    "\n",
    "\n",
    "decoder_layer1_lr = keras.layers.Dense(8,activation=leakyRelu,name='decoder_layer_1_lr',kernel_initializer='normal')(encoder_output_lr)\n",
    "d1_lr = keras.layers.Dense(32, activation=leakyRelu, name='d1_lr',kernel_initializer='normal')(decoder_layer1_lr)             \n",
    "d2_lr = keras.layers.Dense(65, activation=leakyRelu, name='d2_lr',kernel_initializer='normal')(d1_lr)              \n",
    "d3_lr = keras.layers.Dense(160, activation=leakyRelu, name='d3_lr',kernel_initializer='normal')(d2_lr)              \n",
    "d4_lr = keras.layers.Dense(300, activation=leakyRelu, name='d4_lr',kernel_initializer='normal')(d3_lr) \n",
    "\n",
    "decoder_output_lr = keras.layers.Dense(519, activation=leakyRelu, name='decoder_output_lr',kernel_initializer='normal')(d4_lr)\n",
    "autoencoder_lr = keras.Model(encoder_input_lr, decoder_output_lr)\n",
    "\n",
    "\n",
    "# Build decoder 6 layers\n",
    "encode_input = keras.Input((2,), name='Encded_input')\n",
    "\n",
    "decco = autoencoder_lr.layers[-6](encode_input)\n",
    "decco = autoencoder_lr.layers[-5](decco)\n",
    "decco = autoencoder_lr.layers[-4](decco)\n",
    "decco = autoencoder_lr.layers[-3](decco)\n",
    "decco = autoencoder_lr.layers[-2](decco)\n",
    "decco = autoencoder_lr.layers[-1](decco)\n",
    "\n",
    "\n",
    "\n",
    "decoder_lr = keras.Model(encode_input, decco, name='Decoder_lr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "PolyAlanine_leaky_relu (Inpu [(None, 519)]             0         \n",
      "_________________________________________________________________\n",
      "x1_lr (Dense)                (None, 300)               156000    \n",
      "_________________________________________________________________\n",
      "x2_lr (Dense)                (None, 160)               48160     \n",
      "_________________________________________________________________\n",
      "x3_lr (Dense)                (None, 65)                10465     \n",
      "_________________________________________________________________\n",
      "x4_lr (Dense)                (None, 32)                2112      \n",
      "_________________________________________________________________\n",
      "x5_lr (Dense)                (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "encoder_output_lr (Dense)    (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "decoder_layer_1_lr (Dense)   (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "d1_lr (Dense)                (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "d2_lr (Dense)                (None, 65)                2145      \n",
      "_________________________________________________________________\n",
      "d3_lr (Dense)                (None, 160)               10560     \n",
      "_________________________________________________________________\n",
      "d4_lr (Dense)                (None, 300)               48300     \n",
      "_________________________________________________________________\n",
      "decoder_output_lr (Dense)    (None, 519)               156219    \n",
      "=================================================================\n",
      "Total params: 434,555\n",
      "Trainable params: 434,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Decoder_lr\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encded_input (InputLayer)    [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1_lr (Dense)   (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "d1_lr (Dense)                (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "d2_lr (Dense)                (None, 65)                2145      \n",
      "_________________________________________________________________\n",
      "d3_lr (Dense)                (None, 160)               10560     \n",
      "_________________________________________________________________\n",
      "d4_lr (Dense)                (None, 300)               48300     \n",
      "_________________________________________________________________\n",
      "decoder_output_lr (Dense)    (None, 519)               156219    \n",
      "=================================================================\n",
      "Total params: 217,536\n",
      "Trainable params: 217,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 7s 7ms/step - loss: 0.0988 - mse: 0.0988 - val_loss: 0.0828 - val_mse: 0.0828\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0576 - mse: 0.0576 - val_loss: 0.0823 - val_mse: 0.0823\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0540 - mse: 0.0540 - val_loss: 0.0659 - val_mse: 0.0659\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0636 - val_mse: 0.0636\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0565 - val_mse: 0.0565\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0569 - val_mse: 0.0569\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0609 - val_mse: 0.0609\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0603 - val_mse: 0.0603\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0675 - val_mse: 0.0675\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0567 - val_mse: 0.0567\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0617 - val_mse: 0.0617\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0623 - val_mse: 0.0623\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0590 - val_mse: 0.0590\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0628 - val_mse: 0.0628\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0649 - val_mse: 0.0649\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0623 - val_mse: 0.0623\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0669 - val_mse: 0.0669\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0625 - val_mse: 0.0625\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0644 - val_mse: 0.0644\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0634 - val_mse: 0.0634\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0638 - val_mse: 0.0638\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0621 - val_mse: 0.0621\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0647 - val_mse: 0.0647\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0640 - val_mse: 0.0640\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0638 - val_mse: 0.0638\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0638 - val_mse: 0.0638\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0663 - val_mse: 0.0663\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0697 - val_mse: 0.0697\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0651 - val_mse: 0.0651\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0652 - val_mse: 0.0652\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0714 - val_mse: 0.0714\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0671 - val_mse: 0.0671\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0682 - val_mse: 0.0682\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0693 - val_mse: 0.0693\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0677 - val_mse: 0.0677\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0623 - val_mse: 0.0623\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0653 - val_mse: 0.0653\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0685 - val_mse: 0.0685\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0662 - val_mse: 0.0662\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0690 - val_mse: 0.0690\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0680 - val_mse: 0.0680\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0673 - val_mse: 0.0673\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0654 - val_mse: 0.0654\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0694 - val_mse: 0.0694\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0657 - val_mse: 0.0657\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0693 - val_mse: 0.0693\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0701 - val_mse: 0.0701\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0719 - val_mse: 0.0719\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0672 - val_mse: 0.0672\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0737 - val_mse: 0.0737\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0719 - val_mse: 0.0719\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0668 - val_mse: 0.0668\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0730 - val_mse: 0.0730\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0736 - val_mse: 0.0736\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0697 - val_mse: 0.0697\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0744 - val_mse: 0.0744\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0850 - val_mse: 0.0850\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0716 - val_mse: 0.0716\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0672 - val_mse: 0.0672\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0704 - val_mse: 0.0704\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0716 - val_mse: 0.0716\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0718 - val_mse: 0.0718\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0753 - val_mse: 0.0753\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0753 - val_mse: 0.0753\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0782 - val_mse: 0.0782\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0703 - val_mse: 0.0703\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0783 - val_mse: 0.0783\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0734 - val_mse: 0.0734\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0726 - val_mse: 0.0726\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0708 - val_mse: 0.0708\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0732 - val_mse: 0.0732\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0730 - val_mse: 0.0730\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0686 - val_mse: 0.0686\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0746 - val_mse: 0.0746\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0776 - val_mse: 0.0776\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0753 - val_mse: 0.0753\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0743 - val_mse: 0.0743\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0723 - val_mse: 0.0723\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0775 - val_mse: 0.0775\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0731 - val_mse: 0.0731\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0713 - val_mse: 0.0713\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0749 - val_mse: 0.0749\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0754 - val_mse: 0.0754\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0745 - val_mse: 0.0745\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0748 - val_mse: 0.0748\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0737 - val_mse: 0.0737\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0770 - val_mse: 0.0770\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0745 - val_mse: 0.0745\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0726 - val_mse: 0.0726\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0724 - val_mse: 0.0724\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0715 - val_mse: 0.0715\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0760 - val_mse: 0.0760\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0737 - val_mse: 0.0737\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0821 - val_mse: 0.0821\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0732 - val_mse: 0.0732\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0772 - val_mse: 0.0772\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0791 - val_mse: 0.0791\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0781 - val_mse: 0.0781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1a6498b490>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "autoencoder_lr.compile(optimizer=opt, loss='mse',metrics='mse')\n",
    "autoencoder_lr.fit(Coordinates_array_scalled, Coordinates_array_scalled,\n",
    "                        callbacks=[model_checkpoint_callback],\n",
    "                        epochs=100, batch_size=5, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(autoencoder_lr,to_file='AutoEncoderlr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder_lr.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-12dedc63677b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'autoencoder_lr' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "SVG(model_to_dot(autoencoder_lr).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9c49b09e20>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.129487, -2.8409936]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_xyz = []\n",
    "for i in range(Coordinates_array_scalled.shape[0]):\n",
    "    encoded_coordinate = list(encoder_lr.predict(Coordinates_array_scalled[i].reshape((-1, 519)))[0])\n",
    "    encoded_xyz.append(encoded_coordinate)\n",
    "    \n",
    "\n",
    "encoded_xyz[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.129487, -2.8409936]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_xyz[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_xyz_array = np.array(encoded_xyz)\n",
    "encoded_xyz_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('encoded_xyz_array.npy',encoded_xyz_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_xyz_array = np.load('encoded_xyz_array.npy')\n",
    "encoded_xyz_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.129487</td>\n",
       "      <td>-2.840994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.310599</td>\n",
       "      <td>-2.897259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.743897</td>\n",
       "      <td>-2.721105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.570127</td>\n",
       "      <td>-2.977942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.475515</td>\n",
       "      <td>-2.948548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  9.129487 -2.840994\n",
       "1  9.310599 -2.897259\n",
       "2  8.743897 -2.721105\n",
       "3  9.570127 -2.977942\n",
       "4  9.475515 -2.948548"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_xyz_df = pd.DataFrame(encoded_xyz_array)\n",
    "encoded_xyz_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayub/.local/lib/python3.8/site-packages/pandas/core/frame.py:4290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "temp_df = encoded_xyz_df.iloc[1:]\n",
    "temp_df.rename(columns={0: \"y1\", 1: \"y2\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.310599</td>\n",
       "      <td>-2.897259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.743897</td>\n",
       "      <td>-2.721105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.570127</td>\n",
       "      <td>-2.977942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.475515</td>\n",
       "      <td>-2.948548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.345530</td>\n",
       "      <td>-2.908145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         y1        y2\n",
       "1  9.310599 -2.897259\n",
       "2  8.743897 -2.721105\n",
       "3  9.570127 -2.977942\n",
       "4  9.475515 -2.948548\n",
       "5  9.345530 -2.908145"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.129487</td>\n",
       "      <td>-2.840994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.310599</td>\n",
       "      <td>-2.897259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.743897</td>\n",
       "      <td>-2.721105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.570127</td>\n",
       "      <td>-2.977942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.475515</td>\n",
       "      <td>-2.948548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>9.473530</td>\n",
       "      <td>-2.947952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>9.568713</td>\n",
       "      <td>-2.977467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>9.332465</td>\n",
       "      <td>-2.903993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>9.225574</td>\n",
       "      <td>-2.870726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>9.617414</td>\n",
       "      <td>-2.992614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1\n",
       "0     9.129487 -2.840994\n",
       "1     9.310599 -2.897259\n",
       "2     8.743897 -2.721105\n",
       "3     9.570127 -2.977942\n",
       "4     9.475515 -2.948548\n",
       "...        ...       ...\n",
       "4995  9.473530 -2.947952\n",
       "4996  9.568713 -2.977467\n",
       "4997  9.332465 -2.903993\n",
       "4998  9.225574 -2.870726\n",
       "4999  9.617414 -2.992614\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_xyz_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>9.568713</td>\n",
       "      <td>-2.977467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>9.332465</td>\n",
       "      <td>-2.903993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>9.225574</td>\n",
       "      <td>-2.870726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>9.617414</td>\n",
       "      <td>-2.992614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            y1        y2\n",
       "4995  9.568713 -2.977467\n",
       "4996  9.332465 -2.903993\n",
       "4997  9.225574 -2.870726\n",
       "4998  9.617414 -2.992614\n",
       "4999       NaN       NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = temp_df.append({'y1':None,'y2':None},ignore_index=True)\n",
    "temp_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features:(5000, 2) \n",
      "shape of targets:(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'shape of features:{encoded_xyz_df.shape} \\nshape of targets:{temp_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.129487</td>\n",
       "      <td>-2.840994</td>\n",
       "      <td>9.310599</td>\n",
       "      <td>-2.897259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.310599</td>\n",
       "      <td>-2.897259</td>\n",
       "      <td>8.743897</td>\n",
       "      <td>-2.721105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.743897</td>\n",
       "      <td>-2.721105</td>\n",
       "      <td>9.570127</td>\n",
       "      <td>-2.977942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.570127</td>\n",
       "      <td>-2.977942</td>\n",
       "      <td>9.475515</td>\n",
       "      <td>-2.948548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.475515</td>\n",
       "      <td>-2.948548</td>\n",
       "      <td>9.345530</td>\n",
       "      <td>-2.908145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1        y1        y2\n",
       "0  9.129487 -2.840994  9.310599 -2.897259\n",
       "1  9.310599 -2.897259  8.743897 -2.721105\n",
       "2  8.743897 -2.721105  9.570127 -2.977942\n",
       "3  9.570127 -2.977942  9.475515 -2.948548\n",
       "4  9.475515 -2.948548  9.345530 -2.908145"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_encoded_xyz = pd.concat([encoded_xyz_df,temp_df],axis=1)\n",
    "labelled_encoded_xyz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>8.449734</td>\n",
       "      <td>-2.629412</td>\n",
       "      <td>9.473530</td>\n",
       "      <td>-2.947952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>9.473530</td>\n",
       "      <td>-2.947952</td>\n",
       "      <td>9.568713</td>\n",
       "      <td>-2.977467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>9.568713</td>\n",
       "      <td>-2.977467</td>\n",
       "      <td>9.332465</td>\n",
       "      <td>-2.903993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>9.332465</td>\n",
       "      <td>-2.903993</td>\n",
       "      <td>9.225574</td>\n",
       "      <td>-2.870726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>9.225574</td>\n",
       "      <td>-2.870726</td>\n",
       "      <td>9.617414</td>\n",
       "      <td>-2.992614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1        y1        y2\n",
       "4994  8.449734 -2.629412  9.473530 -2.947952\n",
       "4995  9.473530 -2.947952  9.568713 -2.977467\n",
       "4996  9.568713 -2.977467  9.332465 -2.903993\n",
       "4997  9.332465 -2.903993  9.225574 -2.870726\n",
       "4998  9.225574 -2.870726  9.617414 -2.992614"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_encoded_xyz.dropna(inplace=True)\n",
    "labelled_encoded_xyz.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_encoded_xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.129487</td>\n",
       "      <td>-2.840994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.310599</td>\n",
       "      <td>-2.897259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.743897</td>\n",
       "      <td>-2.721105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.570127</td>\n",
       "      <td>-2.977942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.475515</td>\n",
       "      <td>-2.948548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>8.449734</td>\n",
       "      <td>-2.629412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>9.473530</td>\n",
       "      <td>-2.947952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>9.568713</td>\n",
       "      <td>-2.977467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>9.332465</td>\n",
       "      <td>-2.903993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>9.225574</td>\n",
       "      <td>-2.870726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4999 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1\n",
       "0     9.129487 -2.840994\n",
       "1     9.310599 -2.897259\n",
       "2     8.743897 -2.721105\n",
       "3     9.570127 -2.977942\n",
       "4     9.475515 -2.948548\n",
       "...        ...       ...\n",
       "4994  8.449734 -2.629412\n",
       "4995  9.473530 -2.947952\n",
       "4996  9.568713 -2.977467\n",
       "4997  9.332465 -2.903993\n",
       "4998  9.225574 -2.870726\n",
       "\n",
       "[4999 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = labelled_encoded_xyz[[0,1]]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.310599</td>\n",
       "      <td>-2.897259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.743897</td>\n",
       "      <td>-2.721105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.570127</td>\n",
       "      <td>-2.977942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.475515</td>\n",
       "      <td>-2.948548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.345530</td>\n",
       "      <td>-2.908145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>9.473530</td>\n",
       "      <td>-2.947952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>9.568713</td>\n",
       "      <td>-2.977467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>9.332465</td>\n",
       "      <td>-2.903993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>9.225574</td>\n",
       "      <td>-2.870726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>9.617414</td>\n",
       "      <td>-2.992614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4999 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y1        y2\n",
       "0     9.310599 -2.897259\n",
       "1     8.743897 -2.721105\n",
       "2     9.570127 -2.977942\n",
       "3     9.475515 -2.948548\n",
       "4     9.345530 -2.908145\n",
       "...        ...       ...\n",
       "4994  9.473530 -2.947952\n",
       "4995  9.568713 -2.977467\n",
       "4996  9.332465 -2.903993\n",
       "4997  9.225574 -2.870726\n",
       "4998  9.617414 -2.992614\n",
       "\n",
       "[4999 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = labelled_encoded_xyz[['y1','y2']]\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_arr = features.to_numpy()\n",
    "targets_arr = targets.to_numpy()\n",
    "features_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RNN model to predict feature MD simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_arr_reshaped = features_arr.reshape(4999, 1, 2)\n",
    "features_arr_reshaped.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RNN = Sequential()\n",
    "model_RNN.add(LSTM(128,input_shape = (features_arr_reshaped.shape[1:]), return_sequences=True, activation='relu'))\n",
    "model_RNN.add(Dropout(0.2))\n",
    "model_RNN.add(BatchNormalization())\n",
    "\n",
    "model_RNN.add(LSTM(128,input_shape = (features_arr_reshaped.shape[1:]), return_sequences=True, activation='relu'))\n",
    "model_RNN.add(Dropout(0.2))\n",
    "model_RNN.add(BatchNormalization())\n",
    "\n",
    "model_RNN.add(LSTM(128, input_shape=(features_arr_reshaped.shape[1:]), activation='relu'))\n",
    "model_RNN.add(Dropout(0.2))\n",
    "model_RNN.add(BatchNormalization())\n",
    "\n",
    "model_RNN.add(Dense(32, activation='relu'))\n",
    "model_RNN.add(Dropout(0.2))\n",
    "\n",
    "model_RNN.add(Dense(2, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 128)            67072     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 335,970\n",
      "Trainable params: 335,202\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_RNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "model_RNN.compile(optimizer=opt, loss='mse', metrics='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_arr_reshaped = features_arr_reshaped[3999:]\n",
    "train_features_arr_reshaped = features_arr_reshaped[:3999]\n",
    "\n",
    "\n",
    "train_targets_arr = targets_arr[:3999]\n",
    "test_targets_arr = targets_arr[3999:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "500/500 [==============================] - 9s 8ms/step - loss: 26.4778 - accuracy: 0.8163 - val_loss: 6.5678 - val_accuracy: 0.9620\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 10.6813 - accuracy: 0.9035 - val_loss: 4.9271 - val_accuracy: 0.9620\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 9.7506 - accuracy: 0.9117 - val_loss: 4.9138 - val_accuracy: 0.9620\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 8.7295 - accuracy: 0.9152 - val_loss: 5.1123 - val_accuracy: 0.9620\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 8.8642 - accuracy: 0.9111 - val_loss: 5.3485 - val_accuracy: 0.9620\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 8.5349 - accuracy: 0.9040 - val_loss: 5.5810 - val_accuracy: 0.9620\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 8.5915 - accuracy: 0.9036 - val_loss: 4.6804 - val_accuracy: 0.9620\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 8.3836 - accuracy: 0.9043 - val_loss: 4.6621 - val_accuracy: 0.9620\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 8.1728 - accuracy: 0.9053 - val_loss: 4.6356 - val_accuracy: 0.9620\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 8.2495 - accuracy: 0.9127 - val_loss: 4.4439 - val_accuracy: 0.9620\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 8.1757 - accuracy: 0.9110 - val_loss: 4.5479 - val_accuracy: 0.9620\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.9807 - accuracy: 0.9103 - val_loss: 4.4155 - val_accuracy: 0.9620\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.7239 - accuracy: 0.9048 - val_loss: 4.9295 - val_accuracy: 0.9620\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.7308 - accuracy: 0.9080 - val_loss: 4.4708 - val_accuracy: 0.9620\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 7.7244 - accuracy: 0.8981 - val_loss: 4.4704 - val_accuracy: 0.9620\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.7672 - accuracy: 0.9062 - val_loss: 4.4258 - val_accuracy: 0.9620\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.5459 - accuracy: 0.9093 - val_loss: 4.6116 - val_accuracy: 0.9620\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.7780 - accuracy: 0.9141 - val_loss: 4.5722 - val_accuracy: 0.9620\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.7706 - accuracy: 0.9150 - val_loss: 4.6447 - val_accuracy: 0.9620\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 7.6318 - accuracy: 0.9170 - val_loss: 4.7457 - val_accuracy: 0.9620\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 7.4803 - accuracy: 0.8947 - val_loss: 4.5999 - val_accuracy: 0.9620\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 7.3333 - accuracy: 0.9108 - val_loss: 4.4362 - val_accuracy: 0.9620\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.4993 - accuracy: 0.9050 - val_loss: 4.6048 - val_accuracy: 0.9620\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.4126 - accuracy: 0.9051 - val_loss: 4.3406 - val_accuracy: 0.9620\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.4174 - accuracy: 0.9124 - val_loss: 4.4702 - val_accuracy: 0.9620\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.4629 - accuracy: 0.9086 - val_loss: 4.4752 - val_accuracy: 0.9620\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.3446 - accuracy: 0.9100 - val_loss: 4.3656 - val_accuracy: 0.9620\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.2291 - accuracy: 0.9076 - val_loss: 11.7220 - val_accuracy: 0.9480\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.4593 - accuracy: 0.9134 - val_loss: 4.5270 - val_accuracy: 0.9620\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.3173 - accuracy: 0.9120 - val_loss: 4.4739 - val_accuracy: 0.9620\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.2766 - accuracy: 0.9115 - val_loss: 4.4295 - val_accuracy: 0.9620\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 7.1941 - accuracy: 0.9021 - val_loss: 5.0893 - val_accuracy: 0.9620\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 7.0316 - accuracy: 0.8988 - val_loss: 4.6774 - val_accuracy: 0.9620\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 7.2382 - accuracy: 0.9035 - val_loss: 4.4330 - val_accuracy: 0.9620\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 7.2171 - accuracy: 0.9084 - val_loss: 4.6981 - val_accuracy: 0.9620\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.9136 - accuracy: 0.9068 - val_loss: 4.4074 - val_accuracy: 0.9620\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 7.0657 - accuracy: 0.9067 - val_loss: 4.6500 - val_accuracy: 0.9620\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 7.1470 - accuracy: 0.9096 - val_loss: 4.6060 - val_accuracy: 0.9620\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.1601 - accuracy: 0.9042 - val_loss: 4.7375 - val_accuracy: 0.9620\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.1937 - accuracy: 0.9048 - val_loss: 4.5860 - val_accuracy: 0.9620\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.0158 - accuracy: 0.9038 - val_loss: 4.7471 - val_accuracy: 0.9620\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.1559 - accuracy: 0.9046 - val_loss: 4.5616 - val_accuracy: 0.9620\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.9528 - accuracy: 0.9110 - val_loss: 4.5222 - val_accuracy: 0.9620\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.9416 - accuracy: 0.9089 - val_loss: 4.6685 - val_accuracy: 0.9620\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.9968 - accuracy: 0.9132 - val_loss: 4.5334 - val_accuracy: 0.9620\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.1197 - accuracy: 0.9070 - val_loss: 4.3617 - val_accuracy: 0.9620\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.1477 - accuracy: 0.9041 - val_loss: 4.5543 - val_accuracy: 0.9620\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.9606 - accuracy: 0.9079 - val_loss: 4.4280 - val_accuracy: 0.9620\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.9731 - accuracy: 0.9098 - val_loss: 4.4313 - val_accuracy: 0.9620\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.9973 - accuracy: 0.9068 - val_loss: 4.4832 - val_accuracy: 0.9620\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.0080 - accuracy: 0.9030 - val_loss: 4.5164 - val_accuracy: 0.9620\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.7895 - accuracy: 0.9010 - val_loss: 4.5664 - val_accuracy: 0.9620\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.9629 - accuracy: 0.9109 - val_loss: 4.8894 - val_accuracy: 0.9620\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.9096 - accuracy: 0.9073 - val_loss: 4.7329 - val_accuracy: 0.9620\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.8397 - accuracy: 0.9064 - val_loss: 4.5298 - val_accuracy: 0.9620\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.8918 - accuracy: 0.9080 - val_loss: 4.7245 - val_accuracy: 0.9620\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.8798 - accuracy: 0.9022 - val_loss: 4.5690 - val_accuracy: 0.9620\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.8780 - accuracy: 0.9088 - val_loss: 4.4318 - val_accuracy: 0.9620\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.8813 - accuracy: 0.9038 - val_loss: 4.5051 - val_accuracy: 0.9620\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.9576 - accuracy: 0.9095 - val_loss: 4.7880 - val_accuracy: 0.9620\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.0744 - accuracy: 0.9095 - val_loss: 4.7579 - val_accuracy: 0.9620\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 7.0278 - accuracy: 0.9152 - val_loss: 4.5263 - val_accuracy: 0.9620\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.7245 - accuracy: 0.9045 - val_loss: 4.6062 - val_accuracy: 0.9620\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.9392 - accuracy: 0.9110 - val_loss: 4.5372 - val_accuracy: 0.9620\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.8867 - accuracy: 0.9137 - val_loss: 4.4408 - val_accuracy: 0.9620\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.9573 - accuracy: 0.9110 - val_loss: 4.4614 - val_accuracy: 0.9620\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.8167 - accuracy: 0.9000 - val_loss: 4.5922 - val_accuracy: 0.9620\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 6.7525 - accuracy: 0.9081 - val_loss: 4.5622 - val_accuracy: 0.9620\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 6.8358 - accuracy: 0.9003 - val_loss: 4.6927 - val_accuracy: 0.9620\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 6.7163 - accuracy: 0.8970 - val_loss: 4.6115 - val_accuracy: 0.9620\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 6.8622 - accuracy: 0.9059 - val_loss: 4.6034 - val_accuracy: 0.9620\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.7081 - accuracy: 0.9035 - val_loss: 4.5022 - val_accuracy: 0.9620\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.7903 - accuracy: 0.9014 - val_loss: 4.7855 - val_accuracy: 0.9620\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 6.7708 - accuracy: 0.9044 - val_loss: 4.6049 - val_accuracy: 0.9620\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.7561 - accuracy: 0.9004 - val_loss: 4.5920 - val_accuracy: 0.9620\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.7242 - accuracy: 0.8977 - val_loss: 4.6142 - val_accuracy: 0.9620\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.7779 - accuracy: 0.9056 - val_loss: 4.7410 - val_accuracy: 0.9620\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.6100 - accuracy: 0.9031 - val_loss: 4.9437 - val_accuracy: 0.9620\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.7203 - accuracy: 0.9081 - val_loss: 4.7579 - val_accuracy: 0.9620\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.5625 - accuracy: 0.8992 - val_loss: 4.7717 - val_accuracy: 0.9620\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.7296 - accuracy: 0.9096 - val_loss: 4.4957 - val_accuracy: 0.9620\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.7603 - accuracy: 0.8968 - val_loss: 4.8481 - val_accuracy: 0.9620\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.7543 - accuracy: 0.9091 - val_loss: 4.9794 - val_accuracy: 0.9620\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.7903 - accuracy: 0.9058 - val_loss: 5.0293 - val_accuracy: 0.9620\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.6001 - accuracy: 0.9085 - val_loss: 4.8662 - val_accuracy: 0.9620\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.8372 - accuracy: 0.9141 - val_loss: 4.7974 - val_accuracy: 0.9620\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.6833 - accuracy: 0.9014 - val_loss: 4.6703 - val_accuracy: 0.9620\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.5640 - accuracy: 0.9014 - val_loss: 4.5367 - val_accuracy: 0.9620\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.7110 - accuracy: 0.9032 - val_loss: 4.8369 - val_accuracy: 0.9620\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 6.6670 - accuracy: 0.9009 - val_loss: 4.6621 - val_accuracy: 0.9620\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.6783 - accuracy: 0.9017 - val_loss: 4.7016 - val_accuracy: 0.9620\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.7083 - accuracy: 0.9069 - val_loss: 4.8104 - val_accuracy: 0.9620\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.6388 - accuracy: 0.9018 - val_loss: 4.6800 - val_accuracy: 0.9620\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.6278 - accuracy: 0.9107 - val_loss: 4.6755 - val_accuracy: 0.9620\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.6867 - accuracy: 0.9074 - val_loss: 4.6232 - val_accuracy: 0.9620\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.5832 - accuracy: 0.9086 - val_loss: 5.0426 - val_accuracy: 0.9620\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.7041 - accuracy: 0.9029 - val_loss: 4.7304 - val_accuracy: 0.9620\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.6264 - accuracy: 0.8990 - val_loss: 4.6715 - val_accuracy: 0.9620\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.6647 - accuracy: 0.9103 - val_loss: 4.8083 - val_accuracy: 0.9620\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 6.6489 - accuracy: 0.9049 - val_loss: 4.6831 - val_accuracy: 0.9620\n"
     ]
    }
   ],
   "source": [
    "history = model_RNN.fit(\n",
    "        train_features_arr_reshaped,train_targets_arr,\n",
    "        batch_size=8,\n",
    "        epochs=100,\n",
    "        validation_data=(test_features_arr_reshaped,test_targets_arr)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_arr[:3999].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1a98671eb0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.023633,  0.      ]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RNN.predict(train_features_arr_reshaped[22].reshape(1, 1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.849548 , -3.6866357]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_arr_reshaped[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RNN_2 = Sequential()\n",
    "model_RNN_2.add(LSTM(128,input_shape = (features_arr_reshaped.shape[1:]), return_sequences=True, activation='relu'))\n",
    "model_RNN_2.add(Dropout(0.2))\n",
    "# model_RNN.add(BatchNormalization())\n",
    "\n",
    "model_RNN_2.add(LSTM(128,input_shape = (features_arr_reshaped.shape[1:]), return_sequences=True, activation='relu'))\n",
    "model_RNN_2.add(Dropout(0.2))\n",
    "# model_RNN.add(BatchNormalization())\n",
    "\n",
    "model_RNN_2.add(LSTM(128, input_shape=(features_arr_reshaped.shape[1:]), activation='relu'))\n",
    "model_RNN_2.add(Dropout(0.2))\n",
    "# model_RNN.add(BatchNormalization())\n",
    "\n",
    "model_RNN_2.add(Dense(32, activation='relu'))\n",
    "model_RNN_2.add(Dropout(0.2))\n",
    "\n",
    "model_RNN_2.add(Dense(2, activation='tanh'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 1, 128)            67072     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 334,434\n",
      "Trainable params: 334,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_RNN_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45808813, 0.49996203],\n",
       "       [0.46695212, 0.49179205],\n",
       "       [0.4392166 , 0.51737034],\n",
       "       ...,\n",
       "       [0.47958472, 0.48014548],\n",
       "       [0.4680223 , 0.49081418],\n",
       "       [0.46279085, 0.49564478]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_2 = MinMaxScaler()\n",
    "features_arr_scalled = scaler_2.fit_transform(features_arr)\n",
    "features_arr_scalled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46695212, 0.49179205],\n",
       "       [0.4392166 , 0.51737034],\n",
       "       [0.4796539 , 0.48007658],\n",
       "       ...,\n",
       "       [0.4680223 , 0.49081418],\n",
       "       [0.46279085, 0.49564478],\n",
       "       [0.48196825, 0.4779461 ]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets_arr_scalled = scaler_2.fit_transform(targets_arr)\n",
    "targets_arr_scalled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999, 1, 2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_arr_scalled_reshaped = features_arr_scalled.reshape(4999, 1, 2)\n",
    "features_arr_scalled_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 1, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_arr_scalled_reshaped = features_arr_scalled_reshaped[3999:]\n",
    "train_features_arr_scalled_reshaped = features_arr_scalled_reshaped[:3999]\n",
    "\n",
    "\n",
    "train_targets_arr_scalled = targets_arr_scalled[:3999]\n",
    "test_targets_arr_scalled = targets_arr_scalled[3999:]\n",
    "train_features_arr_scalled_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 10s 11ms/step - loss: 0.0817 - accuracy: 0.6508 - val_loss: 0.0015 - val_accuracy: 0.9310\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.0075 - accuracy: 0.9210 - val_loss: 0.0019 - val_accuracy: 0.9380\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.0055 - accuracy: 0.9364 - val_loss: 0.0013 - val_accuracy: 0.9430\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.0046 - accuracy: 0.9407 - val_loss: 0.0013 - val_accuracy: 0.9580\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.0038 - accuracy: 0.9451 - val_loss: 0.0015 - val_accuracy: 0.9260\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.0035 - accuracy: 0.9492 - val_loss: 0.0014 - val_accuracy: 0.9460\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.0032 - accuracy: 0.9435 - val_loss: 0.0012 - val_accuracy: 0.9580\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 0.9500 - val_loss: 0.0013 - val_accuracy: 0.9330\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.0031 - accuracy: 0.9502 - val_loss: 0.0012 - val_accuracy: 0.9430\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 0.9488 - val_loss: 0.0011 - val_accuracy: 0.9430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1a7d6b8fd0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "model_RNN_2.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
    "\n",
    "model_RNN_2.fit(\n",
    "    train_features_arr_scalled_reshaped, train_targets_arr_scalled,\n",
    "    batch_size=8,\n",
    "    epochs=10,\n",
    "    validation_data=(test_features_arr_scalled_reshaped, test_targets_arr_scalled)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = model_RNN_2.predict(test_features_arr_scalled_reshaped[100].reshape(1, 1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.708779, 0.268696], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets_arr_scalled[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ex\n",
    "test_targets_arr_scalled[100].shape\n",
    "ex.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.192404 , -4.5163193], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_encoded = scaler_2.inverse_transform(ex)[0]\n",
    "ex_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.251692, -4.433687], dtype=float32)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_encode = scaler_2.inverse_transform(test_targets_arr_scalled[100].reshape(1,2))[0]\n",
    "ref_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_str = decoder_lr.predict(ex_encoded.reshape(-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_str = decoder_lr.predict(ref_encode.reshape(-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.267151 , 27.842947 , 11.522764 , 15.389928 , 28.177967 ,\n",
       "        11.3359585, 15.715762 , 27.642715 , 11.316745 , 14.729624 ,\n",
       "        27.132113 , 12.005965 , 14.673302 , 28.533709 , 12.47859  ,\n",
       "        13.460607 , 27.571175 , 12.23678  , 15.43778  , 26.310925 ,\n",
       "        14.481485 , 15.519317 , 26.929625 , 15.22007  , 15.22412  ,\n",
       "        25.743021 , 15.079491 , 15.626898 , 25.363335 , 15.254899 ,\n",
       "        15.129934 , 27.533737 , 12.379402 , 16.745893 , 27.63198  ,\n",
       "        11.313536 , 14.746331 , 26.826244 , 11.299416 , 13.5721655,\n",
       "        26.441557 , 12.591184 , 14.890903 , 26.446308 ,  9.8024   ,\n",
       "        15.109693 , 27.159378 , 10.709201 , 13.453961 , 28.36124  ,\n",
       "        10.526259 , 12.586096 , 29.634796 , 10.712047 , 12.679195 ,\n",
       "        28.652029 , 11.064296 , 13.031929 , 28.671349 , 10.307634 ,\n",
       "        15.970868 , 26.014507 , 13.069609 , 15.246571 , 24.409197 ,\n",
       "        12.849051 , 16.387058 , 27.885305 , 15.240382 , 15.496236 ,\n",
       "        28.153992 , 14.027377 , 16.432558 , 28.653128 , 15.757422 ,\n",
       "        16.923729 , 25.187128 , 14.427341 , 16.624674 , 27.845749 ,\n",
       "        17.052126 , 16.693283 , 26.838358 , 15.679089 , 16.573898 ,\n",
       "        29.314812 , 17.352678 , 17.17307  , 27.09818  , 17.539412 ,\n",
       "        16.78672  , 29.971659 , 18.507195 , 16.405735 , 30.859846 ,\n",
       "        18.323584 , 15.947726 , 29.020706 , 16.757212 , 15.136139 ,\n",
       "        28.307438 , 15.257763 , 16.324116 , 29.83093  , 20.177048 ,\n",
       "        16.573828 , 30.687008 , 20.035706 , 14.620806 , 28.018396 ,\n",
       "        20.231796 , 14.908578 , 28.611193 , 19.351206 , 14.547179 ,\n",
       "        27.402918 , 20.19423  , 14.9596195, 28.5135   , 20.062145 ,\n",
       "        15.489396 , 28.196707 , 15.762349 , 14.618842 , 25.359562 ,\n",
       "        16.478472 , 15.376244 , 31.357714 , 14.907949 , 15.660865 ,\n",
       "        32.510906 , 15.359437 , 15.006295 , 31.250185 , 13.697101 ,\n",
       "        13.913282 , 29.179562 , 13.413669 , 14.183209 , 30.625523 ,\n",
       "        13.834027 , 14.263054 , 31.000418 , 13.936719 , 13.264838 ,\n",
       "        30.94822  , 12.313001 , 14.058028 , 31.410543 , 12.244318 ,\n",
       "        15.26912  , 29.921282 , 11.580665 , 15.607812 , 29.68124  ,\n",
       "        12.524426 , 16.554234 , 28.409771 , 10.242525 , 17.55325  ,\n",
       "        27.65264  , 10.212625 , 17.778347 , 28.725924 , 10.5436325,\n",
       "        19.06012  , 28.485014 , 12.19426  , 19.049849 , 27.653507 ,\n",
       "         9.26811  , 18.11429  , 27.579233 ,  9.027343 , 18.920076 ,\n",
       "        29.360298 ,  9.700536 , 18.111832 , 29.043056 , 11.0722275,\n",
       "        19.283377 , 26.398844 , 11.153686 , 19.394672 , 22.546045 ,\n",
       "        11.338541 , 22.386566 , 27.645472 , 11.197872 , 22.287916 ,\n",
       "        29.625017 , 10.861387 , 23.02052  , 25.832949 , 15.077629 ,\n",
       "        22.670246 , 24.057621 , 14.706368 , 23.29076  , 27.953072 ,\n",
       "        18.687073 , 23.56754  , 29.806147 , 19.072275 , 23.665855 ,\n",
       "        29.863167 , 19.029982 , 23.496552 , 29.75996  , 18.738012 ,\n",
       "        22.472664 , 21.674135 , 16.703789 , 24.381092 , 21.451347 ,\n",
       "        17.786783 , 21.50629  , 21.56905  , 15.258291 , 21.590261 ,\n",
       "        22.743069 , 13.939937 , 21.134022 , 20.570372 , 17.635395 ,\n",
       "        21.229149 , 19.169218 , 18.070404 , 20.246397 , 21.545822 ,\n",
       "        18.687014 , 20.180857 , 21.077866 , 18.358568 , 20.725603 ,\n",
       "        21.249697 , 19.866484 , 20.354494 , 21.163975 , 18.573038 ,\n",
       "        20.156345 , 19.519789 , 14.663195 , 20.524172 , 19.494078 ,\n",
       "        14.950774 , 19.059294 , 17.587711 , 16.321665 , 19.892736 ,\n",
       "        18.057657 , 15.935704 , 17.911839 , 17.989393 , 14.243171 ,\n",
       "        17.36896  , 18.342361 , 14.771587 , 17.597572 , 18.96636  ,\n",
       "        14.207946 , 17.83226  , 18.488739 , 14.416262 , 17.34158  ,\n",
       "        19.947033 , 14.9621525, 17.824099 , 17.99156  , 15.771067 ,\n",
       "        19.73876  , 19.604969 , 13.522649 , 18.570509 , 18.650152 ,\n",
       "        14.095124 , 22.2636   , 19.71771  , 13.014304 , 22.92225  ,\n",
       "        19.541784 , 12.806333 , 23.54174  , 20.031607 , 13.176931 ,\n",
       "        25.024603 , 20.761839 , 14.166856 , 21.947126 , 20.603237 ,\n",
       "        12.158539 , 21.825037 , 20.517765 , 11.511911 , 20.774185 ,\n",
       "        20.953041 , 11.651338 , 21.999626 , 20.017658 , 11.895878 ,\n",
       "        23.72847  , 19.368536 , 14.688016 , 20.859226 , 18.560263 ,\n",
       "        14.493792 , 22.976706 , 20.049803 , 15.018929 , 22.955286 ,\n",
       "        21.007683 , 15.218725 , 23.534483 , 20.402985 , 15.911837 ,\n",
       "        24.553257 , 19.036896 , 16.388847 , 23.494146 , 21.710754 ,\n",
       "        16.751993 , 23.379105 , 22.487755 , 17.067162 , 22.490692 ,\n",
       "        22.717886 , 16.70475  , 22.858074 , 22.229544 , 16.577005 ,\n",
       "        18.992937 , 19.66981  , 16.055868 , 19.095333 , 20.596941 ,\n",
       "        15.721    , 16.667854 , 18.586033 , 16.955267 , 17.323023 ,\n",
       "        17.960499 , 15.859621 , 15.593417 , 15.866564 , 15.815832 ,\n",
       "        15.167589 , 18.96967  , 16.244755 , 14.899524 , 17.198877 ,\n",
       "        15.0437355, 14.431241 , 17.50448  , 15.606117 , 14.632146 ,\n",
       "        17.85156  , 15.279106 , 14.482066 , 18.67169  , 16.076244 ,\n",
       "        15.577043 , 22.407595 , 15.357099 , 15.470433 , 22.008533 ,\n",
       "        15.640847 , 16.826895 , 26.35341  , 14.344934 , 16.096292 ,\n",
       "        26.511835 , 14.402328 , 16.584545 , 27.80016  , 14.296109 ,\n",
       "        16.900003 , 25.904144 , 13.3211   , 16.906542 , 28.025751 ,\n",
       "        13.094036 , 17.799152 , 27.08327  , 13.367145 , 17.345606 ,\n",
       "        28.115353 , 15.434154 , 17.176033 , 28.714298 , 14.6028   ,\n",
       "        18.177515 , 27.83983  , 14.468519 , 19.18443  , 27.12387  ,\n",
       "        14.521825 , 18.159128 , 27.959349 , 15.783699 , 17.334496 ,\n",
       "        28.475822 , 16.331217 , 19.262608 , 27.018955 , 15.9464245,\n",
       "        20.120502 , 25.811747 , 15.433498 , 20.067478 , 28.058548 ,\n",
       "        17.023195 , 19.71988  , 26.592188 , 17.13012  , 19.592619 ,\n",
       "        27.007542 , 16.010757 , 20.086119 , 26.968908 , 16.381193 ,\n",
       "        18.831905 , 26.957752 , 17.834278 , 18.918749 , 26.279093 ,\n",
       "        18.94814  , 18.127483 , 25.97309  , 18.482714 , 17.397066 ,\n",
       "        25.836552 , 16.54756  , 16.804363 , 23.647636 , 19.314167 ,\n",
       "        16.6514   , 23.209427 , 19.543722 , 15.645504 , 21.58897  ,\n",
       "        18.5941   , 15.43525  , 21.539072 , 17.900026 , 15.909017 ,\n",
       "        20.360865 , 18.31644  , 16.565512 , 21.18196  , 18.522882 ,\n",
       "        17.495605 , 20.717524 , 18.556599 , 17.570639 , 19.80856  ,\n",
       "        18.382832 , 17.591387 , 18.96268  , 20.440992 , 17.216187 ,\n",
       "        19.65949  , 21.657843 , 18.001867 , 17.113184 , 21.055109 ,\n",
       "        18.60981  , 17.936956 , 21.641375 , 18.479427 , 19.167784 ,\n",
       "        22.477694 , 18.287909 , 20.125868 , 22.712803 , 18.57453  ,\n",
       "        18.129772 , 22.375927 , 18.2172   , 18.673191 , 22.612251 ,\n",
       "        17.128063 , 15.464673 , 22.353195 , 16.193296 , 15.462768 ,\n",
       "        23.535044 , 18.102423 , 15.792597 , 24.124908 , 18.6133   ,\n",
       "        16.786749 , 23.922598 , 17.007717 , 15.077352 , 24.287603 ,\n",
       "        16.422487 , 11.826641 , 25.144676 , 16.545044 , 10.447823 ,\n",
       "        25.398144 , 16.163439 ,  8.853949 , 24.635681 , 16.830217 ,\n",
       "         9.305128 , 25.125656 , 16.877024 , 10.434636 , 24.695711 ,\n",
       "        18.501959 , 15.438773 , 26.68672  , 18.283985 , 15.568754 ,\n",
       "        26.384691 , 18.751184 , 16.42708  , 26.918793 ]], dtype=float32)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_str = scaler.inverse_transform(prediction_str)\n",
    "example_str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.652829 , 27.340548 , 11.873145 , 15.76709  , 27.619707 ,\n",
       "       11.688905 , 16.16653  , 26.954266 , 11.675816 , 15.100935 ,\n",
       "       26.413712 , 12.389911 , 14.999104 , 28.150894 , 12.773823 ,\n",
       "       13.843614 , 27.158216 , 12.607333 , 15.742098 , 25.84985  ,\n",
       "       14.790377 , 15.852038 , 26.408937 , 15.674476 , 15.524383 ,\n",
       "       25.227734 , 15.432287 , 16.008966 , 24.797268 , 15.586333 ,\n",
       "       15.289619 , 27.11459  , 12.581851 , 16.863426 , 27.190382 ,\n",
       "       11.454717 , 14.9116745, 26.594852 , 11.473743 , 13.759824 ,\n",
       "       26.13964  , 12.703546 , 14.891165 , 26.168991 ,  9.819021 ,\n",
       "       15.0801   , 26.992855 , 10.677311 , 13.335392 , 28.133825 ,\n",
       "       10.527484 , 12.572941 , 29.375177 , 10.70689  , 12.59451  ,\n",
       "       28.444965 , 11.045417 , 12.946164 , 28.37522  , 10.272015 ,\n",
       "       15.746598 , 25.615053 , 12.923789 , 14.982015 , 23.847986 ,\n",
       "       12.667581 , 16.074026 , 27.754484 , 15.376696 , 15.261437 ,\n",
       "       27.972408 , 14.31692  , 16.033522 , 28.03772  , 15.868866 ,\n",
       "       16.514023 , 24.388721 , 14.23015  , 16.360958 , 27.036755 ,\n",
       "       17.509613 , 16.36406  , 26.035799 , 15.989206 , 16.331226 ,\n",
       "       28.677036 , 17.829796 , 16.857336 , 26.252417 , 17.960676 ,\n",
       "       16.256079 , 29.49858  , 18.75706  , 15.829941 , 30.695303 ,\n",
       "       18.43438  , 15.436498 , 28.079313 , 16.727982 , 14.728316 ,\n",
       "       27.40764  , 15.286291 , 15.895836 , 28.971556 , 20.404238 ,\n",
       "       16.16582  , 30.048958 , 20.2552   , 14.215308 , 27.01375  ,\n",
       "       20.606287 , 14.56453  , 27.634935 , 19.810534 , 14.118095 ,\n",
       "       26.194277 , 20.693752 , 14.599412 , 27.470589 , 20.417334 ,\n",
       "       15.068709 , 27.234869 , 15.351477 , 14.170447 , 24.137217 ,\n",
       "       16.261806 , 15.004019 , 30.95184  , 14.522632 , 15.295104 ,\n",
       "       32.203773 , 15.251485 , 14.651323 , 30.667828 , 13.455206 ,\n",
       "       13.538615 , 28.440598 , 13.0416   , 14.110015 , 30.231974 ,\n",
       "       13.734714 , 14.19881  , 30.687313 , 13.851155 , 13.247428 ,\n",
       "       30.591028 , 12.184597 , 13.983286 , 31.074745 , 12.1021805,\n",
       "       15.058091 , 29.306875 , 11.409703 , 15.486836 , 29.102444 ,\n",
       "       12.232808 , 16.216976 , 27.596935 , 10.098428 , 17.155523 ,\n",
       "       26.786448 , 10.093273 , 17.976343 , 27.927397 , 10.458435 ,\n",
       "       19.695734 , 27.660706 , 12.021621 , 19.306475 , 26.848349 ,\n",
       "        9.2444   , 18.286303 , 26.714138 ,  9.083431 , 19.266085 ,\n",
       "       28.451857 ,  9.711611 , 18.150356 , 28.20138  , 11.066601 ,\n",
       "       19.270857 , 25.527555 , 11.080143 , 18.889158 , 21.416998 ,\n",
       "       11.223565 , 23.11529  , 26.775654 , 11.029235 , 23.110462 ,\n",
       "       28.661428 , 10.701513 , 23.754686 , 24.847393 , 15.254123 ,\n",
       "       23.160877 , 22.992842 , 14.913099 , 23.965534 , 27.102337 ,\n",
       "       19.271418 , 24.248163 , 28.990974 , 19.729717 , 24.240131 ,\n",
       "       29.076693 , 19.657005 , 24.149405 , 29.073269 , 19.200922 ,\n",
       "       23.027466 , 20.374384 , 17.002357 , 24.86435  , 20.27278  ,\n",
       "       18.21696  , 22.130737 , 20.250874 , 15.397215 , 22.341534 ,\n",
       "       21.583208 , 13.774761 , 21.608742 , 19.27857  , 17.79498  ,\n",
       "       21.728203 , 17.734741 , 18.14221  , 20.938492 , 20.220919 ,\n",
       "       19.02315  , 20.949217 , 19.83956  , 18.701452 , 21.385862 ,\n",
       "       20.015272 , 20.250216 , 21.10614  , 19.974491 , 18.98862  ,\n",
       "       20.423714 , 18.30002  , 14.5621805, 20.655668 , 18.531467 ,\n",
       "       14.858812 , 19.038132 , 16.19162  , 16.476906 , 19.982502 ,\n",
       "       16.577871 , 16.011309 , 17.489578 , 16.904575 , 14.245401 ,\n",
       "       16.818552 , 17.541172 , 14.700968 , 17.219553 , 17.933653 ,\n",
       "       14.249437 , 17.497583 , 17.473515 , 14.258718 , 16.905874 ,\n",
       "       18.843714 , 15.165356 , 17.520947 , 16.962114 , 15.8968315,\n",
       "       19.191706 , 18.739902 , 13.441475 , 18.027807 , 17.950142 ,\n",
       "       14.027596 , 22.154758 , 18.715208 , 12.849683 , 22.960415 ,\n",
       "       18.395432 , 12.671098 , 23.37568  , 19.158306 , 13.109936 ,\n",
       "       25.077822 , 19.983002 , 14.22589  , 21.667988 , 19.703602 ,\n",
       "       12.021764 , 21.509897 , 19.785564 , 11.35089  , 20.42094  ,\n",
       "       20.079674 , 11.428475 , 21.716938 , 19.092054 , 11.726497 ,\n",
       "       23.637928 , 18.451511 , 14.430378 , 20.397171 , 17.667912 ,\n",
       "       14.179264 , 23.0058   , 19.160854 , 14.708767 , 23.08654  ,\n",
       "       20.21135  , 15.080515 , 23.522232 , 19.739819 , 15.580431 ,\n",
       "       24.604206 , 18.358448 , 16.174234 , 23.697432 , 20.932722 ,\n",
       "       16.420061 , 23.570404 , 21.810223 , 16.740429 , 22.576883 ,\n",
       "       22.073357 , 16.316921 , 23.121496 , 21.48385  , 16.26182  ,\n",
       "       18.427292 , 19.045881 , 15.764987 , 18.552977 , 20.248878 ,\n",
       "       15.361903 , 16.211756 , 17.742386 , 16.741333 , 16.873846 ,\n",
       "       17.095337 , 15.5787735, 15.237772 , 15.264942 , 15.641961 ,\n",
       "       14.868908 , 18.45182  , 15.961437 , 14.591867 , 16.468079 ,\n",
       "       14.929409 , 14.09371  , 16.858217 , 15.405267 , 14.327818 ,\n",
       "       17.215881 , 15.077809 , 14.1031   , 18.004398 , 15.95965  ,\n",
       "       15.206428 , 22.538166 , 15.254181 , 15.0226755, 22.19459  ,\n",
       "       15.442449 , 16.405586 , 26.875477 , 14.256742 , 15.698371 ,\n",
       "       26.846498 , 14.240309 , 16.11304  , 28.922947 , 14.181884 ,\n",
       "       16.456121 , 27.015917 , 13.157028 , 16.385136 , 29.111296 ,\n",
       "       12.856    , 17.290909 , 28.213108 , 13.104369 , 16.86067  ,\n",
       "       29.1529   , 15.214256 , 16.742002 , 29.947977 , 14.224798 ,\n",
       "       17.715858 , 29.082138 , 14.3001   , 18.665106 , 28.347061 ,\n",
       "       14.307829 , 17.68533  , 29.178093 , 15.54585  , 16.86327  ,\n",
       "       29.558254 , 16.090582 , 18.618328 , 28.130423 , 15.521813 ,\n",
       "       19.387934 , 26.988413 , 14.942508 , 19.404238 , 29.02088  ,\n",
       "       16.590929 , 18.994122 , 27.30427  , 16.66568  , 18.970818 ,\n",
       "       27.97371  , 15.520608 , 19.446423 , 27.81314  , 15.876692 ,\n",
       "       18.171404 , 28.085476 , 17.411427 , 18.371555 , 27.238197 ,\n",
       "       18.506464 , 17.548496 , 27.15343  , 18.012918 , 16.875483 ,\n",
       "       27.132889 , 16.118994 , 16.311152 , 24.718203 , 18.74706  ,\n",
       "       16.197187 , 23.976757 , 18.9888   , 15.331785 , 22.504974 ,\n",
       "       18.140823 , 15.138559 , 22.528282 , 17.493956 , 15.551749 ,\n",
       "       21.142096 , 17.96056  , 16.234772 , 22.048252 , 18.100542 ,\n",
       "       17.018261 , 21.67444  , 17.979998 , 17.078335 , 20.783754 ,\n",
       "       17.795809 , 17.033405 , 19.773447 , 19.774324 , 16.70156  ,\n",
       "       20.210838 , 20.911217 , 17.563412 , 17.8293   , 20.411257 ,\n",
       "       18.15876  , 18.771713 , 21.080023 , 18.001953 , 19.6587   ,\n",
       "       21.741035 , 17.856466 , 20.6696   , 22.006413 , 18.133675 ,\n",
       "       18.607845 , 21.633738 , 17.79702  , 19.165277 , 21.843916 ,\n",
       "       16.671312 , 15.837542 , 21.736483 , 15.714028 , 15.622939 ,\n",
       "       23.010021 , 17.658087 , 16.160995 , 23.738888 , 18.246403 ,\n",
       "       17.398275 , 23.347782 , 16.591904 , 15.495979 , 24.005232 ,\n",
       "       15.980279 , 11.662822 , 24.906029 , 16.138094 , 10.038436 ,\n",
       "       25.499096 , 15.751818 ,  8.253479 , 24.741196 , 16.408861 ,\n",
       "        8.876522 , 25.151825 , 16.447498 , 10.118117 , 24.824224 ,\n",
       "       18.137701 , 15.949878 , 26.639608 , 17.881348 , 16.227732 ,\n",
       "       26.271477 , 18.398256 , 16.921093 , 27.057922 ], dtype=float32)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_str = scaler.inverse_transform(ref_str)\n",
    "ref_str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.43, 21.8 , 35.94, 17.1 , 22.75, 35.88, 17.46, 21.6 , 36.93,\n",
       "       18.35, 21.69, 35.54, 16.52, 20.86, 35.28, 16.6 , 21.01, 34.21,\n",
       "       16.91, 19.32, 35.62, 16.5 , 19.  , 36.58, 16.31, 18.75, 34.92,\n",
       "       17.95, 19.02, 35.47, 15.15, 21.2 , 35.88, 14.99, 22.05, 36.77,\n",
       "       14.11, 20.58, 35.39, 14.24, 19.89, 34.66, 12.78, 20.54, 35.96,\n",
       "       12.73, 21.17, 36.85, 11.77, 20.94, 34.89, 11.68, 20.22, 34.08,\n",
       "       10.86, 21.19, 35.44, 12.12, 21.85, 34.42, 12.31, 19.13, 36.45,\n",
       "       12.41, 18.21, 35.6 , 11.84, 19.04, 37.68, 11.79, 19.89, 38.22,\n",
       "       11.22, 17.83, 38.23, 11.74, 16.92, 37.93, 11.18, 17.86, 39.78,\n",
       "       10.6 , 18.71, 40.13, 10.72, 16.98, 40.22, 12.18, 17.91, 40.21,\n",
       "        9.81, 17.63, 37.81,  9.17, 18.63, 37.54,  9.37, 16.33, 37.69,\n",
       "       10.16, 15.71, 37.79,  8.03, 15.93, 37.33,  7.78, 16.29, 36.33,\n",
       "        8.2 , 14.45, 37.2 ,  7.22, 14.04, 36.94,  8.88, 14.19, 36.39,\n",
       "        8.42, 14.  , 38.17,  7.09, 16.29, 38.53,  7.44, 16.18, 39.71,\n",
       "        5.82, 16.68, 38.15,  5.61, 16.59, 37.17,  4.72, 16.88, 39.1 ,\n",
       "        5.01, 16.64, 40.12,  4.29, 18.39, 38.97,  4.11, 18.59, 40.03,\n",
       "        5.11, 18.99, 38.57,  3.4 , 18.63, 38.39,  3.52, 15.97, 38.74,\n",
       "        3.46, 15.42, 37.62,  2.54, 15.78, 39.64,  2.5 , 16.37, 40.45,\n",
       "        1.47, 14.81, 39.42,  1.94, 13.86, 39.18,  0.68, 14.52, 40.72,\n",
       "        0.55, 15.47, 41.23, 49.29, 13.92, 40.61,  1.2 , 13.85, 41.4 ,\n",
       "        0.47, 15.06, 38.26, 49.24, 14.15, 37.85,  0.37, 16.33, 37.9 ,\n",
       "        1.07, 17.  , 38.19, 48.95, 16.86, 36.91, 48.08, 16.21, 36.75,\n",
       "       48.49, 18.27, 37.38, 47.81, 18.14, 38.21, 49.39, 18.85, 37.6 ,\n",
       "       47.94, 18.89, 36.68,  0.28, 16.93, 35.63,  1.47, 17.33, 35.75,\n",
       "       49.14, 16.78, 34.48, 48.15, 16.57, 34.43,  0.26, 16.9 , 33.12,\n",
       "        1.28, 17.28, 33.16,  0.17, 15.46, 32.48, 48.71, 14.97, 32.58,\n",
       "        0.47, 15.47, 31.44,  0.92, 14.81, 32.93, 48.97, 17.83, 32.2 ,\n",
       "        0.07, 18.32, 31.22, 47.69, 18.08, 32.52, 47.32, 17.56, 33.31,\n",
       "       46.68, 18.87, 31.69, 46.91, 18.68, 30.64, 45.29, 18.32, 32.01,\n",
       "       44.99, 18.26, 33.05, 44.47, 18.88, 31.57, 45.12, 17.31, 31.64,\n",
       "       46.65, 20.35, 32.14, 47.17, 20.75, 33.19, 45.98, 21.14, 31.38,\n",
       "       45.7 , 20.77, 30.48, 45.59, 22.52, 31.77, 46.43, 23.1 , 32.15,\n",
       "       45.14, 23.37, 30.55, 44.51, 22.74, 29.92, 44.59, 24.27, 30.82,\n",
       "       46.03, 23.64, 29.99, 44.56, 22.38, 32.95, 43.85, 21.38, 33.03,\n",
       "       44.46, 23.4 , 33.85, 44.99, 24.22, 33.56, 43.8 , 23.57, 35.1 ,\n",
       "       44.44, 23.11, 35.85, 43.64, 25.09, 35.53, 44.62, 25.56, 35.48,\n",
       "       42.97, 25.63, 34.86, 43.11, 25.18, 36.48, 42.49, 22.73, 35.15,\n",
       "       42.38, 21.69, 35.82, 41.53, 23.12, 34.36, 41.74, 23.84, 33.68,\n",
       "       40.18, 22.66, 34.58, 40.  , 22.67, 35.66, 39.26, 23.66, 33.91,\n",
       "       38.22, 23.44, 34.15, 39.34, 24.69, 34.23, 39.33, 23.63, 32.82,\n",
       "       39.95, 21.24, 34.02, 38.99, 20.64, 34.45, 40.81, 20.76, 33.11,\n",
       "       41.56, 21.4 , 32.88, 40.85, 19.48, 32.44, 39.82, 19.17, 32.27,\n",
       "       41.42, 19.54, 30.99, 40.69, 19.86, 30.25, 42.35, 20.11, 31.02,\n",
       "       41.84, 18.56, 30.77, 41.51, 18.43, 33.35, 41.18, 17.29, 33.12,\n",
       "       42.49, 18.79, 34.22, 42.66, 19.78, 34.28, 43.16, 18.06, 35.27,\n",
       "       43.46, 17.03, 35.09, 44.43, 18.83, 35.73, 44.23, 19.78, 36.23,\n",
       "       45.1 , 18.25, 36.37, 45.04, 19.17, 34.89, 42.28, 17.91, 36.53,\n",
       "       42.31, 16.92, 37.27, 41.55, 19.03, 36.86, 41.74, 19.9 , 36.39,\n",
       "       40.61, 19.06, 37.96, 41.08, 18.61, 38.84, 40.18, 20.51, 38.19,\n",
       "       41.12, 21.06, 38.32, 39.75, 21.11, 37.39, 39.66, 20.58, 39.15,\n",
       "       39.3 , 18.31, 37.61, 38.68, 17.86, 38.54, 38.95, 18.21, 36.33,\n",
       "       39.53, 18.66, 35.63, 37.78, 17.44, 35.82, 37.04, 17.71, 36.58,\n",
       "       37.29, 17.91, 34.42, 36.85, 18.9 , 34.34, 38.06, 17.76, 33.67,\n",
       "       36.57, 17.19, 34.04, 38.16, 15.99, 35.89, 39.17, 15.6 , 35.36,\n",
       "       37.22, 15.17, 36.38, 36.31, 15.55, 36.61, 37.2 , 13.72, 36.25,\n",
       "       37.79, 13.51, 35.36, 37.85, 12.93, 37.44, 38.88, 13.2 , 37.68,\n",
       "       37.27, 13.08, 38.35, 37.85, 11.88, 37.16, 35.78, 13.28, 36.04,\n",
       "       34.86, 14.14, 36.1 , 35.52, 12.03, 35.97])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example_str.shape\n",
    "\n",
    "Coordinates_array[4100][1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173, 3)\n",
      "173\n",
      "[[15.652829, 27.340548, 11.873145], [15.76709, 27.619707, 11.688905], [16.16653, 26.954266, 11.675816], [15.100935, 26.413712, 12.389911], [14.999104, 28.150894, 12.773823], [13.843614, 27.158216, 12.607333], [15.742098, 25.84985, 14.790377], [15.852038, 26.408937, 15.674476], [15.524383, 25.227734, 15.432287], [16.008966, 24.797268, 15.586333], [15.289619, 27.11459, 12.581851], [16.863426, 27.190382, 11.454717], [14.9116745, 26.594852, 11.473743], [13.759824, 26.13964, 12.703546], [14.891165, 26.168991, 9.819021], [15.0801, 26.992855, 10.677311], [13.335392, 28.133825, 10.527484], [12.572941, 29.375177, 10.70689], [12.59451, 28.444965, 11.045417], [12.946164, 28.37522, 10.272015], [15.746598, 25.615053, 12.923789], [14.982015, 23.847986, 12.667581], [16.074026, 27.754484, 15.376696], [15.261437, 27.972408, 14.31692], [16.033522, 28.03772, 15.868866], [16.514023, 24.388721, 14.23015], [16.360958, 27.036755, 17.509613], [16.36406, 26.035799, 15.989206], [16.331226, 28.677036, 17.829796], [16.857336, 26.252417, 17.960676], [16.256079, 29.49858, 18.75706], [15.829941, 30.695303, 18.43438], [15.436498, 28.079313, 16.727982], [14.728316, 27.40764, 15.286291], [15.895836, 28.971556, 20.404238], [16.16582, 30.048958, 20.2552], [14.215308, 27.01375, 20.606287], [14.56453, 27.634935, 19.810534], [14.118095, 26.194277, 20.693752], [14.599412, 27.470589, 20.417334], [15.068709, 27.234869, 15.351477], [14.170447, 24.137217, 16.261806], [15.004019, 30.95184, 14.522632], [15.295104, 32.203773, 15.251485], [14.651323, 30.667828, 13.455206], [13.538615, 28.440598, 13.0416], [14.110015, 30.231974, 13.734714], [14.19881, 30.687313, 13.851155], [13.247428, 30.591028, 12.184597], [13.983286, 31.074745, 12.1021805], [15.058091, 29.306875, 11.409703], [15.486836, 29.102444, 12.232808], [16.216976, 27.596935, 10.098428], [17.155523, 26.786448, 10.093273], [17.976343, 27.927397, 10.458435], [19.695734, 27.660706, 12.021621], [19.306475, 26.848349, 9.2444], [18.286303, 26.714138, 9.083431], [19.266085, 28.451857, 9.711611], [18.150356, 28.20138, 11.066601], [19.270857, 25.527555, 11.080143], [18.889158, 21.416998, 11.223565], [23.11529, 26.775654, 11.029235], [23.110462, 28.661428, 10.701513], [23.754686, 24.847393, 15.254123], [23.160877, 22.992842, 14.913099], [23.965534, 27.102337, 19.271418], [24.248163, 28.990974, 19.729717], [24.240131, 29.076693, 19.657005], [24.149405, 29.073269, 19.200922], [23.027466, 20.374384, 17.002357], [24.86435, 20.27278, 18.21696], [22.130737, 20.250874, 15.397215], [22.341534, 21.583208, 13.774761], [21.608742, 19.27857, 17.79498], [21.728203, 17.734741, 18.14221], [20.938492, 20.220919, 19.02315], [20.949217, 19.83956, 18.701452], [21.385862, 20.015272, 20.250216], [21.10614, 19.974491, 18.98862], [20.423714, 18.30002, 14.5621805], [20.655668, 18.531467, 14.858812], [19.038132, 16.19162, 16.476906], [19.982502, 16.577871, 16.011309], [17.489578, 16.904575, 14.245401], [16.818552, 17.541172, 14.700968], [17.219553, 17.933653, 14.249437], [17.497583, 17.473515, 14.258718], [16.905874, 18.843714, 15.165356], [17.520947, 16.962114, 15.8968315], [19.191706, 18.739902, 13.441475], [18.027807, 17.950142, 14.027596], [22.154758, 18.715208, 12.849683], [22.960415, 18.395432, 12.671098], [23.37568, 19.158306, 13.109936], [25.077822, 19.983002, 14.22589], [21.667988, 19.703602, 12.021764], [21.509897, 19.785564, 11.35089], [20.42094, 20.079674, 11.428475], [21.716938, 19.092054, 11.726497], [23.637928, 18.451511, 14.430378], [20.397171, 17.667912, 14.179264], [23.0058, 19.160854, 14.708767], [23.08654, 20.21135, 15.080515], [23.522232, 19.739819, 15.580431], [24.604206, 18.358448, 16.174234], [23.697432, 20.932722, 16.420061], [23.570404, 21.810223, 16.740429], [22.576883, 22.073357, 16.316921], [23.121496, 21.48385, 16.26182], [18.427292, 19.045881, 15.764987], [18.552977, 20.248878, 15.361903], [16.211756, 17.742386, 16.741333], [16.873846, 17.095337, 15.5787735], [15.237772, 15.264942, 15.641961], [14.868908, 18.45182, 15.961437], [14.591867, 16.468079, 14.929409], [14.09371, 16.858217, 15.405267], [14.327818, 17.215881, 15.077809], [14.1031, 18.004398, 15.95965], [15.206428, 22.538166, 15.254181], [15.0226755, 22.19459, 15.442449], [16.405586, 26.875477, 14.256742], [15.698371, 26.846498, 14.240309], [16.11304, 28.922947, 14.181884], [16.456121, 27.015917, 13.157028], [16.385136, 29.111296, 12.856], [17.290909, 28.213108, 13.104369], [16.86067, 29.1529, 15.214256], [16.742002, 29.947977, 14.224798], [17.715858, 29.082138, 14.3001], [18.665106, 28.347061, 14.307829], [17.68533, 29.178093, 15.54585], [16.86327, 29.558254, 16.090582], [18.618328, 28.130423, 15.521813], [19.387934, 26.988413, 14.942508], [19.404238, 29.02088, 16.590929], [18.994122, 27.30427, 16.66568], [18.970818, 27.97371, 15.520608], [19.446423, 27.81314, 15.876692], [18.171404, 28.085476, 17.411427], [18.371555, 27.238197, 18.506464], [17.548496, 27.15343, 18.012918], [16.875483, 27.132889, 16.118994], [16.311152, 24.718203, 18.74706], [16.197187, 23.976757, 18.9888], [15.331785, 22.504974, 18.140823], [15.138559, 22.528282, 17.493956], [15.551749, 21.142096, 17.96056], [16.234772, 22.048252, 18.100542], [17.018261, 21.67444, 17.979998], [17.078335, 20.783754, 17.795809], [17.033405, 19.773447, 19.774324], [16.70156, 20.210838, 20.911217], [17.563412, 17.8293, 20.411257], [18.15876, 18.771713, 21.080023], [18.001953, 19.6587, 21.741035], [17.856466, 20.6696, 22.006413], [18.133675, 18.607845, 21.633738], [17.79702, 19.165277, 21.843916], [16.671312, 15.837542, 21.736483], [15.714028, 15.622939, 23.010021], [17.658087, 16.160995, 23.738888], [18.246403, 17.398275, 23.347782], [16.591904, 15.495979, 24.005232], [15.980279, 11.662822, 24.906029], [16.138094, 10.038436, 25.499096], [15.751818, 8.253479, 24.741196], [16.408861, 8.876522, 25.151825], [16.447498, 10.118117, 24.824224], [18.137701, 15.949878, 26.639608], [17.881348, 16.227732, 26.271477], [18.398256, 16.921093, 27.057922]]\n"
     ]
    }
   ],
   "source": [
    "stop = 0 #df_all = pd.concat\n",
    "row_data = []\n",
    "ref_data = []\n",
    "row_count = 0\n",
    "\n",
    "for i in list(ref_str[0]):\n",
    "    # print(dat)\n",
    "    # print(stop)\n",
    "\n",
    "    row_data.append(i)\n",
    "    if row_count == 2:\n",
    "        ref_data.append(row_data)\n",
    "        row_data = []\n",
    "        row_count = 0\n",
    "        continue\n",
    "    row_count += 1\n",
    "    stop += 1\n",
    "\n",
    "graph_ref = pd.DataFrame(ref_data, columns=['X', 'Y', 'Z'])\n",
    "print(graph_ref.shape)\n",
    "print(len(ref_data))\n",
    "print(ref_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173, 3)\n",
      "173\n",
      "[[15.267151, 27.842947, 11.522764], [15.389928, 28.177967, 11.3359585], [15.715762, 27.642715, 11.316745], [14.729624, 27.132113, 12.005965], [14.673302, 28.533709, 12.47859], [13.460607, 27.571175, 12.23678], [15.43778, 26.310925, 14.481485], [15.519317, 26.929625, 15.22007], [15.22412, 25.743021, 15.079491], [15.626898, 25.363335, 15.254899], [15.129934, 27.533737, 12.379402], [16.745893, 27.63198, 11.313536], [14.746331, 26.826244, 11.299416], [13.5721655, 26.441557, 12.591184], [14.890903, 26.446308, 9.8024], [15.109693, 27.159378, 10.709201], [13.453961, 28.36124, 10.526259], [12.586096, 29.634796, 10.712047], [12.679195, 28.652029, 11.064296], [13.031929, 28.671349, 10.307634], [15.970868, 26.014507, 13.069609], [15.246571, 24.409197, 12.849051], [16.387058, 27.885305, 15.240382], [15.496236, 28.153992, 14.027377], [16.432558, 28.653128, 15.757422], [16.923729, 25.187128, 14.427341], [16.624674, 27.845749, 17.052126], [16.693283, 26.838358, 15.679089], [16.573898, 29.314812, 17.352678], [17.17307, 27.09818, 17.539412], [16.78672, 29.971659, 18.507195], [16.405735, 30.859846, 18.323584], [15.947726, 29.020706, 16.757212], [15.136139, 28.307438, 15.257763], [16.324116, 29.83093, 20.177048], [16.573828, 30.687008, 20.035706], [14.620806, 28.018396, 20.231796], [14.908578, 28.611193, 19.351206], [14.547179, 27.402918, 20.19423], [14.9596195, 28.5135, 20.062145], [15.489396, 28.196707, 15.762349], [14.618842, 25.359562, 16.478472], [15.376244, 31.357714, 14.907949], [15.660865, 32.510906, 15.359437], [15.006295, 31.250185, 13.697101], [13.913282, 29.179562, 13.413669], [14.183209, 30.625523, 13.834027], [14.263054, 31.000418, 13.936719], [13.264838, 30.94822, 12.313001], [14.058028, 31.410543, 12.244318], [15.26912, 29.921282, 11.580665], [15.607812, 29.68124, 12.524426], [16.554234, 28.409771, 10.242525], [17.55325, 27.65264, 10.212625], [17.778347, 28.725924, 10.5436325], [19.06012, 28.485014, 12.19426], [19.049849, 27.653507, 9.26811], [18.11429, 27.579233, 9.027343], [18.920076, 29.360298, 9.700536], [18.111832, 29.043056, 11.0722275], [19.283377, 26.398844, 11.153686], [19.394672, 22.546045, 11.338541], [22.386566, 27.645472, 11.197872], [22.287916, 29.625017, 10.861387], [23.02052, 25.832949, 15.077629], [22.670246, 24.057621, 14.706368], [23.29076, 27.953072, 18.687073], [23.56754, 29.806147, 19.072275], [23.665855, 29.863167, 19.029982], [23.496552, 29.75996, 18.738012], [22.472664, 21.674135, 16.703789], [24.381092, 21.451347, 17.786783], [21.50629, 21.56905, 15.258291], [21.590261, 22.743069, 13.939937], [21.134022, 20.570372, 17.635395], [21.229149, 19.169218, 18.070404], [20.246397, 21.545822, 18.687014], [20.180857, 21.077866, 18.358568], [20.725603, 21.249697, 19.866484], [20.354494, 21.163975, 18.573038], [20.156345, 19.519789, 14.663195], [20.524172, 19.494078, 14.950774], [19.059294, 17.587711, 16.321665], [19.892736, 18.057657, 15.935704], [17.911839, 17.989393, 14.243171], [17.36896, 18.342361, 14.771587], [17.597572, 18.96636, 14.207946], [17.83226, 18.488739, 14.416262], [17.34158, 19.947033, 14.9621525], [17.824099, 17.99156, 15.771067], [19.73876, 19.604969, 13.522649], [18.570509, 18.650152, 14.095124], [22.2636, 19.71771, 13.014304], [22.92225, 19.541784, 12.806333], [23.54174, 20.031607, 13.176931], [25.024603, 20.761839, 14.166856], [21.947126, 20.603237, 12.158539], [21.825037, 20.517765, 11.511911], [20.774185, 20.953041, 11.651338], [21.999626, 20.017658, 11.895878], [23.72847, 19.368536, 14.688016], [20.859226, 18.560263, 14.493792], [22.976706, 20.049803, 15.018929], [22.955286, 21.007683, 15.218725], [23.534483, 20.402985, 15.911837], [24.553257, 19.036896, 16.388847], [23.494146, 21.710754, 16.751993], [23.379105, 22.487755, 17.067162], [22.490692, 22.717886, 16.70475], [22.858074, 22.229544, 16.577005], [18.992937, 19.66981, 16.055868], [19.095333, 20.596941, 15.721], [16.667854, 18.586033, 16.955267], [17.323023, 17.960499, 15.859621], [15.593417, 15.866564, 15.815832], [15.167589, 18.96967, 16.244755], [14.899524, 17.198877, 15.0437355], [14.431241, 17.50448, 15.606117], [14.632146, 17.85156, 15.279106], [14.482066, 18.67169, 16.076244], [15.577043, 22.407595, 15.357099], [15.470433, 22.008533, 15.640847], [16.826895, 26.35341, 14.344934], [16.096292, 26.511835, 14.402328], [16.584545, 27.80016, 14.296109], [16.900003, 25.904144, 13.3211], [16.906542, 28.025751, 13.094036], [17.799152, 27.08327, 13.367145], [17.345606, 28.115353, 15.434154], [17.176033, 28.714298, 14.6028], [18.177515, 27.83983, 14.468519], [19.18443, 27.12387, 14.521825], [18.159128, 27.959349, 15.783699], [17.334496, 28.475822, 16.331217], [19.262608, 27.018955, 15.9464245], [20.120502, 25.811747, 15.433498], [20.067478, 28.058548, 17.023195], [19.71988, 26.592188, 17.13012], [19.592619, 27.007542, 16.010757], [20.086119, 26.968908, 16.381193], [18.831905, 26.957752, 17.834278], [18.918749, 26.279093, 18.94814], [18.127483, 25.97309, 18.482714], [17.397066, 25.836552, 16.54756], [16.804363, 23.647636, 19.314167], [16.6514, 23.209427, 19.543722], [15.645504, 21.58897, 18.5941], [15.43525, 21.539072, 17.900026], [15.909017, 20.360865, 18.31644], [16.565512, 21.18196, 18.522882], [17.495605, 20.717524, 18.556599], [17.570639, 19.80856, 18.382832], [17.591387, 18.96268, 20.440992], [17.216187, 19.65949, 21.657843], [18.001867, 17.113184, 21.055109], [18.60981, 17.936956, 21.641375], [18.479427, 19.167784, 22.477694], [18.287909, 20.125868, 22.712803], [18.57453, 18.129772, 22.375927], [18.2172, 18.673191, 22.612251], [17.128063, 15.464673, 22.353195], [16.193296, 15.462768, 23.535044], [18.102423, 15.792597, 24.124908], [18.6133, 16.786749, 23.922598], [17.007717, 15.077352, 24.287603], [16.422487, 11.826641, 25.144676], [16.545044, 10.447823, 25.398144], [16.163439, 8.853949, 24.635681], [16.830217, 9.305128, 25.125656], [16.877024, 10.434636, 24.695711], [18.501959, 15.438773, 26.68672], [18.283985, 15.568754, 26.384691], [18.751184, 16.42708, 26.918793]]\n"
     ]
    }
   ],
   "source": [
    "stop = 0\n",
    "row_data = []\n",
    "predicted_data = []\n",
    "row_count = 0\n",
    "\n",
    "for i in list(example_str[0]):\n",
    "    # print(dat)\n",
    "    # print(stop)\n",
    "\n",
    "    row_data.append(i)\n",
    "    if row_count == 2:\n",
    "        predicted_data.append(row_data)\n",
    "        row_data = []\n",
    "        row_count = 0\n",
    "        continue\n",
    "    row_count += 1\n",
    "    stop += 1\n",
    "\n",
    "graph_predicted = pd.DataFrame(predicted_data, columns=['X', 'Y', 'Z'])\n",
    "print(graph_predicted.shape)\n",
    "print(len(predicted_data))\n",
    "print(predicted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X          Y          Z\n",
      "0  15.267151  27.842947  11.522764\n",
      "1  15.389928  28.177967  11.335958\n",
      "2  15.715762  27.642715  11.316745\n",
      "3  14.729624  27.132113  12.005965\n",
      "4  14.673302  28.533709  12.478590\n",
      "           X          Y          Z\n",
      "0  15.652829  27.340548  11.873145\n",
      "1  15.767090  27.619707  11.688905\n",
      "2  16.166531  26.954266  11.675816\n",
      "3  15.100935  26.413712  12.389911\n",
      "4  14.999104  28.150894  12.773823\n"
     ]
    }
   ],
   "source": [
    "print(graph_predicted.head())\n",
    "print(graph_ref.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATOM\t1\tN\tALA\tX\t41\t17.43\t21.8\t35.94\t0.00\tSYST\n",
      "0\n",
      "ATOM\t2\tH1\tALA\tX\t41\t17.1\t22.75\t35.88\t0.00\tSYST\n",
      "1\n",
      "ATOM\t3\tH2\tALA\tX\t41\t17.46\t21.6\t36.93\t0.00\tSYST\n",
      "2\n",
      "ATOM\t4\tH3\tALA\tX\t41\t18.35\t21.69\t35.54\t0.00\tSYST\n",
      "3\n",
      "ATOM\t5\tCA\tALA\tX\t41\t16.52\t20.86\t35.28\t0.00\tSYST\n",
      "4\n",
      "ATOM\t6\tHA\tALA\tX\t41\t16.6\t21.01\t34.21\t0.00\tSYST\n",
      "5\n",
      "ATOM\t7\tCB\tALA\tX\t41\t16.91\t19.32\t35.62\t0.00\tSYST\n",
      "6\n",
      "ATOM\t8\tHB1\tALA\tX\t41\t16.5\t19.0\t36.58\t0.00\tSYST\n",
      "7\n",
      "ATOM\t9\tHB2\tALA\tX\t41\t16.31\t18.75\t34.92\t0.00\tSYST\n",
      "8\n",
      "ATOM\t10\tHB3\tALA\tX\t41\t17.95\t19.02\t35.47\t0.00\tSYST\n",
      "9\n",
      "ATOM\t11\tC\tALA\tX\t41\t15.15\t21.2\t35.88\t0.00\tSYST\n",
      "10\n",
      "ATOM\t12\tO\tALA\tX\t41\t14.99\t22.05\t36.77\t0.00\tSYST\n",
      "11\n",
      "ATOM\t13\tN\tALA\tX\t42\t14.11\t20.58\t35.39\t0.00\tSYST\n",
      "12\n",
      "ATOM\t14\tH\tALA\tX\t42\t14.24\t19.89\t34.66\t0.00\tSYST\n",
      "13\n",
      "ATOM\t15\tCA\tALA\tX\t42\t12.78\t20.54\t35.96\t0.00\tSYST\n",
      "14\n",
      "ATOM\t16\tHA\tALA\tX\t42\t12.73\t21.17\t36.85\t0.00\tSYST\n",
      "15\n",
      "ATOM\t17\tCB\tALA\tX\t42\t11.77\t20.94\t34.89\t0.00\tSYST\n",
      "16\n",
      "ATOM\t18\tHB1\tALA\tX\t42\t11.68\t20.22\t34.08\t0.00\tSYST\n",
      "17\n",
      "ATOM\t19\tHB2\tALA\tX\t42\t10.86\t21.19\t35.44\t0.00\tSYST\n",
      "18\n",
      "ATOM\t20\tHB3\tALA\tX\t42\t12.12\t21.85\t34.42\t0.00\tSYST\n",
      "19\n",
      "ATOM\t21\tC\tALA\tX\t42\t12.31\t19.13\t36.45\t0.00\tSYST\n",
      "20\n",
      "ATOM\t22\tO\tALA\tX\t42\t12.41\t18.21\t35.6\t0.00\tSYST\n",
      "21\n",
      "ATOM\t23\tN\tALA\tX\t43\t11.84\t19.04\t37.68\t0.00\tSYST\n",
      "22\n",
      "ATOM\t24\tH\tALA\tX\t43\t11.79\t19.89\t38.22\t0.00\tSYST\n",
      "23\n",
      "ATOM\t25\tCA\tALA\tX\t43\t11.22\t17.83\t38.23\t0.00\tSYST\n",
      "24\n",
      "ATOM\t26\tHA\tALA\tX\t43\t11.74\t16.92\t37.93\t0.00\tSYST\n",
      "25\n",
      "ATOM\t27\tCB\tALA\tX\t43\t11.18\t17.86\t39.78\t0.00\tSYST\n",
      "26\n",
      "ATOM\t28\tHB1\tALA\tX\t43\t10.6\t18.71\t40.13\t0.00\tSYST\n",
      "27\n",
      "ATOM\t29\tHB2\tALA\tX\t43\t10.72\t16.98\t40.22\t0.00\tSYST\n",
      "28\n",
      "ATOM\t30\tHB3\tALA\tX\t43\t12.18\t17.91\t40.21\t0.00\tSYST\n",
      "29\n",
      "ATOM\t31\tC\tALA\tX\t43\t9.81\t17.63\t37.81\t0.00\tSYST\n",
      "30\n",
      "ATOM\t32\tO\tALA\tX\t43\t9.17\t18.63\t37.54\t0.00\tSYST\n",
      "31\n",
      "ATOM\t33\tN\tALA\tX\t44\t9.37\t16.33\t37.69\t0.00\tSYST\n",
      "32\n",
      "ATOM\t34\tH\tALA\tX\t44\t10.16\t15.71\t37.79\t0.00\tSYST\n",
      "33\n",
      "ATOM\t35\tCA\tALA\tX\t44\t8.03\t15.93\t37.33\t0.00\tSYST\n",
      "34\n",
      "ATOM\t36\tHA\tALA\tX\t44\t7.78\t16.29\t36.33\t0.00\tSYST\n",
      "35\n",
      "ATOM\t37\tCB\tALA\tX\t44\t8.2\t14.45\t37.2\t0.00\tSYST\n",
      "36\n",
      "ATOM\t38\tHB1\tALA\tX\t44\t7.22\t14.04\t36.94\t0.00\tSYST\n",
      "37\n",
      "ATOM\t39\tHB2\tALA\tX\t44\t8.88\t14.19\t36.39\t0.00\tSYST\n",
      "38\n",
      "ATOM\t40\tHB3\tALA\tX\t44\t8.42\t14.0\t38.17\t0.00\tSYST\n",
      "39\n",
      "ATOM\t41\tC\tALA\tX\t44\t7.09\t16.29\t38.53\t0.00\tSYST\n",
      "40\n",
      "ATOM\t42\tO\tALA\tX\t44\t7.44\t16.18\t39.71\t0.00\tSYST\n",
      "41\n",
      "ATOM\t43\tN\tALA\tX\t45\t5.82\t16.68\t38.15\t0.00\tSYST\n",
      "42\n",
      "ATOM\t44\tH\tALA\tX\t45\t5.61\t16.59\t37.17\t0.00\tSYST\n",
      "43\n",
      "ATOM\t45\tCA\tALA\tX\t45\t4.72\t16.88\t39.1\t0.00\tSYST\n",
      "44\n",
      "ATOM\t46\tHA\tALA\tX\t45\t5.01\t16.64\t40.12\t0.00\tSYST\n",
      "45\n",
      "ATOM\t47\tCB\tALA\tX\t45\t4.29\t18.39\t38.97\t0.00\tSYST\n",
      "46\n",
      "ATOM\t48\tHB1\tALA\tX\t45\t4.11\t18.59\t40.03\t0.00\tSYST\n",
      "47\n",
      "ATOM\t49\tHB2\tALA\tX\t45\t5.11\t18.99\t38.57\t0.00\tSYST\n",
      "48\n",
      "ATOM\t50\tHB3\tALA\tX\t45\t3.4\t18.63\t38.39\t0.00\tSYST\n",
      "49\n",
      "ATOM\t51\tC\tALA\tX\t45\t3.52\t15.97\t38.74\t0.00\tSYST\n",
      "50\n",
      "ATOM\t52\tO\tALA\tX\t45\t3.46\t15.42\t37.62\t0.00\tSYST\n",
      "51\n",
      "ATOM\t53\tN\tALA\tX\t46\t2.54\t15.78\t39.64\t0.00\tSYST\n",
      "52\n",
      "ATOM\t54\tH\tALA\tX\t46\t2.5\t16.37\t40.45\t0.00\tSYST\n",
      "53\n",
      "ATOM\t55\tCA\tALA\tX\t46\t1.47\t14.81\t39.42\t0.00\tSYST\n",
      "54\n",
      "ATOM\t56\tHA\tALA\tX\t46\t1.94\t13.86\t39.18\t0.00\tSYST\n",
      "55\n",
      "ATOM\t57\tCB\tALA\tX\t46\t0.68\t14.52\t40.72\t0.00\tSYST\n",
      "56\n",
      "ATOM\t58\tHB1\tALA\tX\t46\t0.55\t15.47\t41.23\t0.00\tSYST\n",
      "57\n",
      "ATOM\t59\tHB2\tALA\tX\t46\t49.29\t13.92\t40.61\t0.00\tSYST\n",
      "58\n",
      "ATOM\t60\tHB3\tALA\tX\t46\t1.2\t13.85\t41.4\t0.00\tSYST\n",
      "59\n",
      "ATOM\t61\tC\tALA\tX\t46\t0.47\t15.06\t38.26\t0.00\tSYST\n",
      "60\n",
      "ATOM\t62\tO\tALA\tX\t46\t49.24\t14.15\t37.85\t0.00\tSYST\n",
      "61\n",
      "ATOM\t63\tN\tALA\tX\t47\t0.37\t16.33\t37.9\t0.00\tSYST\n",
      "62\n",
      "ATOM\t64\tH\tALA\tX\t47\t1.07\t17.0\t38.19\t0.00\tSYST\n",
      "63\n",
      "ATOM\t65\tCA\tALA\tX\t47\t48.95\t16.86\t36.91\t0.00\tSYST\n",
      "64\n",
      "ATOM\t66\tHA\tALA\tX\t47\t48.08\t16.21\t36.75\t0.00\tSYST\n",
      "65\n",
      "ATOM\t67\tCB\tALA\tX\t47\t48.49\t18.27\t37.38\t0.00\tSYST\n",
      "66\n",
      "ATOM\t68\tHB1\tALA\tX\t47\t47.81\t18.14\t38.21\t0.00\tSYST\n",
      "67\n",
      "ATOM\t69\tHB2\tALA\tX\t47\t49.39\t18.85\t37.6\t0.00\tSYST\n",
      "68\n",
      "ATOM\t70\tHB3\tALA\tX\t47\t47.94\t18.89\t36.68\t0.00\tSYST\n",
      "69\n",
      "ATOM\t71\tC\tALA\tX\t47\t0.28\t16.93\t35.63\t0.00\tSYST\n",
      "70\n",
      "ATOM\t72\tO\tALA\tX\t47\t1.47\t17.33\t35.75\t0.00\tSYST\n",
      "71\n",
      "ATOM\t73\tN\tALA\tX\t48\t49.14\t16.78\t34.48\t0.00\tSYST\n",
      "72\n",
      "ATOM\t74\tH\tALA\tX\t48\t48.15\t16.57\t34.43\t0.00\tSYST\n",
      "73\n",
      "ATOM\t75\tCA\tALA\tX\t48\t0.26\t16.9\t33.12\t0.00\tSYST\n",
      "74\n",
      "ATOM\t76\tHA\tALA\tX\t48\t1.28\t17.28\t33.16\t0.00\tSYST\n",
      "75\n",
      "ATOM\t77\tCB\tALA\tX\t48\t0.17\t15.46\t32.48\t0.00\tSYST\n",
      "76\n",
      "ATOM\t78\tHB1\tALA\tX\t48\t48.71\t14.97\t32.58\t0.00\tSYST\n",
      "77\n",
      "ATOM\t79\tHB2\tALA\tX\t48\t0.47\t15.47\t31.44\t0.00\tSYST\n",
      "78\n",
      "ATOM\t80\tHB3\tALA\tX\t48\t0.92\t14.81\t32.93\t0.00\tSYST\n",
      "79\n",
      "ATOM\t81\tC\tALA\tX\t48\t48.97\t17.83\t32.2\t0.00\tSYST\n",
      "80\n",
      "ATOM\t82\tO\tALA\tX\t48\t0.07\t18.32\t31.22\t0.00\tSYST\n",
      "81\n",
      "ATOM\t83\tN\tALA\tX\t49\t47.69\t18.08\t32.52\t0.00\tSYST\n",
      "82\n",
      "ATOM\t84\tH\tALA\tX\t49\t47.32\t17.56\t33.31\t0.00\tSYST\n",
      "83\n",
      "ATOM\t85\tCA\tALA\tX\t49\t46.68\t18.87\t31.69\t0.00\tSYST\n",
      "84\n",
      "ATOM\t86\tHA\tALA\tX\t49\t46.91\t18.68\t30.64\t0.00\tSYST\n",
      "85\n",
      "ATOM\t87\tCB\tALA\tX\t49\t45.29\t18.32\t32.01\t0.00\tSYST\n",
      "86\n",
      "ATOM\t88\tHB1\tALA\tX\t49\t44.99\t18.26\t33.05\t0.00\tSYST\n",
      "87\n",
      "ATOM\t89\tHB2\tALA\tX\t49\t44.47\t18.88\t31.57\t0.00\tSYST\n",
      "88\n",
      "ATOM\t90\tHB3\tALA\tX\t49\t45.12\t17.31\t31.64\t0.00\tSYST\n",
      "89\n",
      "ATOM\t91\tC\tALA\tX\t49\t46.65\t20.35\t32.14\t0.00\tSYST\n",
      "90\n",
      "ATOM\t92\tO\tALA\tX\t49\t47.17\t20.75\t33.19\t0.00\tSYST\n",
      "91\n",
      "ATOM\t93\tN\tALA\tX\t50\t45.98\t21.14\t31.38\t0.00\tSYST\n",
      "92\n",
      "ATOM\t94\tH\tALA\tX\t50\t45.7\t20.77\t30.48\t0.00\tSYST\n",
      "93\n",
      "ATOM\t95\tCA\tALA\tX\t50\t45.59\t22.52\t31.77\t0.00\tSYST\n",
      "94\n",
      "ATOM\t96\tHA\tALA\tX\t50\t46.43\t23.1\t32.15\t0.00\tSYST\n",
      "95\n",
      "ATOM\t97\tCB\tALA\tX\t50\t45.14\t23.37\t30.55\t0.00\tSYST\n",
      "96\n",
      "ATOM\t98\tHB1\tALA\tX\t50\t44.51\t22.74\t29.92\t0.00\tSYST\n",
      "97\n",
      "ATOM\t99\tHB2\tALA\tX\t50\t44.59\t24.27\t30.82\t0.00\tSYST\n",
      "98\n",
      "ATOM\t100\tHB3\tALA\tX\t50\t46.03\t23.64\t29.99\t0.00\tSYST\n",
      "99\n",
      "ATOM\t101\tC\tALA\tX\t50\t44.56\t22.38\t32.95\t0.00\tSYST\n",
      "100\n",
      "ATOM\t102\tO\tALA\tX\t50\t43.85\t21.38\t33.03\t0.00\tSYST\n",
      "101\n",
      "ATOM\t103\tN\tALA\tX\t51\t44.46\t23.4\t33.85\t0.00\tSYST\n",
      "102\n",
      "ATOM\t104\tH\tALA\tX\t51\t44.99\t24.22\t33.56\t0.00\tSYST\n",
      "103\n",
      "ATOM\t105\tCA\tALA\tX\t51\t43.8\t23.57\t35.1\t0.00\tSYST\n",
      "104\n",
      "ATOM\t106\tHA\tALA\tX\t51\t44.44\t23.11\t35.85\t0.00\tSYST\n",
      "105\n",
      "ATOM\t107\tCB\tALA\tX\t51\t43.64\t25.09\t35.53\t0.00\tSYST\n",
      "106\n",
      "ATOM\t108\tHB1\tALA\tX\t51\t44.62\t25.56\t35.48\t0.00\tSYST\n",
      "107\n",
      "ATOM\t109\tHB2\tALA\tX\t51\t42.97\t25.63\t34.86\t0.00\tSYST\n",
      "108\n",
      "ATOM\t110\tHB3\tALA\tX\t51\t43.11\t25.18\t36.48\t0.00\tSYST\n",
      "109\n",
      "ATOM\t111\tC\tALA\tX\t51\t42.49\t22.73\t35.15\t0.00\tSYST\n",
      "110\n",
      "ATOM\t112\tO\tALA\tX\t51\t42.38\t21.69\t35.82\t0.00\tSYST\n",
      "111\n",
      "ATOM\t113\tN\tALA\tX\t52\t41.53\t23.12\t34.36\t0.00\tSYST\n",
      "112\n",
      "ATOM\t114\tH\tALA\tX\t52\t41.74\t23.84\t33.68\t0.00\tSYST\n",
      "113\n",
      "ATOM\t115\tCA\tALA\tX\t52\t40.18\t22.66\t34.58\t0.00\tSYST\n",
      "114\n",
      "ATOM\t116\tHA\tALA\tX\t52\t40.0\t22.67\t35.66\t0.00\tSYST\n",
      "115\n",
      "ATOM\t117\tCB\tALA\tX\t52\t39.26\t23.66\t33.91\t0.00\tSYST\n",
      "116\n",
      "ATOM\t118\tHB1\tALA\tX\t52\t38.22\t23.44\t34.15\t0.00\tSYST\n",
      "117\n",
      "ATOM\t119\tHB2\tALA\tX\t52\t39.34\t24.69\t34.23\t0.00\tSYST\n",
      "118\n",
      "ATOM\t120\tHB3\tALA\tX\t52\t39.33\t23.63\t32.82\t0.00\tSYST\n",
      "119\n",
      "ATOM\t121\tC\tALA\tX\t52\t39.95\t21.24\t34.02\t0.00\tSYST\n",
      "120\n",
      "ATOM\t122\tO\tALA\tX\t52\t38.99\t20.64\t34.45\t0.00\tSYST\n",
      "121\n",
      "ATOM\t123\tN\tALA\tX\t53\t40.81\t20.76\t33.11\t0.00\tSYST\n",
      "122\n",
      "ATOM\t124\tH\tALA\tX\t53\t41.56\t21.4\t32.88\t0.00\tSYST\n",
      "123\n",
      "ATOM\t125\tCA\tALA\tX\t53\t40.85\t19.48\t32.44\t0.00\tSYST\n",
      "124\n",
      "ATOM\t126\tHA\tALA\tX\t53\t39.82\t19.17\t32.27\t0.00\tSYST\n",
      "125\n",
      "ATOM\t127\tCB\tALA\tX\t53\t41.42\t19.54\t30.99\t0.00\tSYST\n",
      "126\n",
      "ATOM\t128\tHB1\tALA\tX\t53\t40.69\t19.86\t30.25\t0.00\tSYST\n",
      "127\n",
      "ATOM\t129\tHB2\tALA\tX\t53\t42.35\t20.11\t31.02\t0.00\tSYST\n",
      "128\n",
      "ATOM\t130\tHB3\tALA\tX\t53\t41.84\t18.56\t30.77\t0.00\tSYST\n",
      "129\n",
      "ATOM\t131\tC\tALA\tX\t53\t41.51\t18.43\t33.35\t0.00\tSYST\n",
      "130\n",
      "ATOM\t132\tO\tALA\tX\t53\t41.18\t17.29\t33.12\t0.00\tSYST\n",
      "131\n",
      "ATOM\t133\tN\tALA\tX\t54\t42.49\t18.79\t34.22\t0.00\tSYST\n",
      "132\n",
      "ATOM\t134\tH\tALA\tX\t54\t42.66\t19.78\t34.28\t0.00\tSYST\n",
      "133\n",
      "ATOM\t135\tCA\tALA\tX\t54\t43.16\t18.06\t35.27\t0.00\tSYST\n",
      "134\n",
      "ATOM\t136\tHA\tALA\tX\t54\t43.46\t17.03\t35.09\t0.00\tSYST\n",
      "135\n",
      "ATOM\t137\tCB\tALA\tX\t54\t44.43\t18.83\t35.73\t0.00\tSYST\n",
      "136\n",
      "ATOM\t138\tHB1\tALA\tX\t54\t44.23\t19.78\t36.23\t0.00\tSYST\n",
      "137\n",
      "ATOM\t139\tHB2\tALA\tX\t54\t45.1\t18.25\t36.37\t0.00\tSYST\n",
      "138\n",
      "ATOM\t140\tHB3\tALA\tX\t54\t45.04\t19.17\t34.89\t0.00\tSYST\n",
      "139\n",
      "ATOM\t141\tC\tALA\tX\t54\t42.28\t17.91\t36.53\t0.00\tSYST\n",
      "140\n",
      "ATOM\t142\tO\tALA\tX\t54\t42.31\t16.92\t37.27\t0.00\tSYST\n",
      "141\n",
      "ATOM\t143\tN\tALA\tX\t55\t41.55\t19.03\t36.86\t0.00\tSYST\n",
      "142\n",
      "ATOM\t144\tH\tALA\tX\t55\t41.74\t19.9\t36.39\t0.00\tSYST\n",
      "143\n",
      "ATOM\t145\tCA\tALA\tX\t55\t40.61\t19.06\t37.96\t0.00\tSYST\n",
      "144\n",
      "ATOM\t146\tHA\tALA\tX\t55\t41.08\t18.61\t38.84\t0.00\tSYST\n",
      "145\n",
      "ATOM\t147\tCB\tALA\tX\t55\t40.18\t20.51\t38.19\t0.00\tSYST\n",
      "146\n",
      "ATOM\t148\tHB1\tALA\tX\t55\t41.12\t21.06\t38.32\t0.00\tSYST\n",
      "147\n",
      "ATOM\t149\tHB2\tALA\tX\t55\t39.75\t21.11\t37.39\t0.00\tSYST\n",
      "148\n",
      "ATOM\t150\tHB3\tALA\tX\t55\t39.66\t20.58\t39.15\t0.00\tSYST\n",
      "149\n",
      "ATOM\t151\tC\tALA\tX\t55\t39.3\t18.31\t37.61\t0.00\tSYST\n",
      "150\n",
      "ATOM\t152\tO\tALA\tX\t55\t38.68\t17.86\t38.54\t0.00\tSYST\n",
      "151\n",
      "ATOM\t153\tN\tALA\tX\t56\t38.95\t18.21\t36.33\t0.00\tSYST\n",
      "152\n",
      "ATOM\t154\tH\tALA\tX\t56\t39.53\t18.66\t35.63\t0.00\tSYST\n",
      "153\n",
      "ATOM\t155\tCA\tALA\tX\t56\t37.78\t17.44\t35.82\t0.00\tSYST\n",
      "154\n",
      "ATOM\t156\tHA\tALA\tX\t56\t37.04\t17.71\t36.58\t0.00\tSYST\n",
      "155\n",
      "ATOM\t157\tCB\tALA\tX\t56\t37.29\t17.91\t34.42\t0.00\tSYST\n",
      "156\n",
      "ATOM\t158\tHB1\tALA\tX\t56\t36.85\t18.9\t34.34\t0.00\tSYST\n",
      "157\n",
      "ATOM\t159\tHB2\tALA\tX\t56\t38.06\t17.76\t33.67\t0.00\tSYST\n",
      "158\n",
      "ATOM\t160\tHB3\tALA\tX\t56\t36.57\t17.19\t34.04\t0.00\tSYST\n",
      "159\n",
      "ATOM\t161\tC\tALA\tX\t56\t38.16\t15.99\t35.89\t0.00\tSYST\n",
      "160\n",
      "ATOM\t162\tO\tALA\tX\t56\t39.17\t15.6\t35.36\t0.00\tSYST\n",
      "161\n",
      "ATOM\t163\tN\tALA\tX\t57\t37.22\t15.17\t36.38\t0.00\tSYST\n",
      "162\n",
      "ATOM\t164\tH\tALA\tX\t57\t36.31\t15.55\t36.61\t0.00\tSYST\n",
      "163\n",
      "ATOM\t165\tCA\tALA\tX\t57\t37.2\t13.72\t36.25\t0.00\tSYST\n",
      "164\n",
      "ATOM\t166\tHA\tALA\tX\t57\t37.79\t13.51\t35.36\t0.00\tSYST\n",
      "165\n",
      "ATOM\t167\tCB\tALA\tX\t57\t37.85\t12.93\t37.44\t0.00\tSYST\n",
      "166\n",
      "ATOM\t168\tHB1\tALA\tX\t57\t38.88\t13.2\t37.68\t0.00\tSYST\n",
      "167\n",
      "ATOM\t169\tHB2\tALA\tX\t57\t37.27\t13.08\t38.35\t0.00\tSYST\n",
      "168\n",
      "ATOM\t170\tHB3\tALA\tX\t57\t37.85\t11.88\t37.16\t0.00\tSYST\n",
      "169\n",
      "ATOM\t171\tC\tALA\tX\t57\t35.78\t13.28\t36.04\t0.00\tSYST\n",
      "170\n",
      "ATOM\t172\tO1\tALA\tX\t57\t34.86\t14.14\t36.1\t0.00\tSYST\n",
      "171\n",
      "ATOM\t173\tO2\tALA\tX\t57\t35.52\t12.03\t35.97\t0.00\tSYST\n",
      "172\n"
     ]
    }
   ],
   "source": [
    "PDB = 'example_pdb.pdb'\n",
    "\n",
    "\n",
    "\n",
    "with open(PDB, newline='') as f:\n",
    "    pdb_file = csv.reader(f, delimiter='\\t')\n",
    "    temp_list = []\n",
    "# pdb_file[:6]\n",
    "# print(len(pdb_file))\n",
    "    row = []\n",
    "    full_data = []\n",
    "    counter = 0\n",
    "    pdb_output = ''\n",
    "    for line in pdb_file:\n",
    "\n",
    "        \n",
    "        if 'ATOM' not in line[0]:\n",
    "            pdb_output += ''.join(line) + '\\n'\n",
    "        elif 'ATOM' in line[0]:\n",
    "            line = line[0].split()\n",
    "            predicted_coordinates = list(graph_predicted.iloc[counter])\n",
    "            predicted_coordinates = [str(i) for i in predicted_coordinates]\n",
    "            # line = [i for i in line if i != '']\n",
    "            line = line[:6] + predicted_coordinates + line[10:]\n",
    "            line = '\\t'.join(line)\n",
    "            pdb_output += line + '\\n'\n",
    "            print(line)\n",
    "            print(counter)\n",
    "            counter +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 3)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predicted_polyA_3.pdb', 'w') as f:\n",
    "    f.write(pdb_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_predicted.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSD(df_predict, df_ref):\n",
    "    predict_arr = df_predict.to_numpy()\n",
    "    ref_arr = df_ref.to_numpy()\n",
    "    n = df_ref.shape[0]  # df_ref.shape[0] * df_ref.shape[1]\n",
    "    return np.sqrt(np.sum((np.array(predict_arr)-np.array(ref_arr))**2))/n\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32, 32, 58])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.matrix([[1, 2,3], [3, 4,2]])\n",
    "b = np.matrix([[5, 6,6], [7, 8,9]])\n",
    "sum((np.array(a)-np.array(b))**2)/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8408935028645435"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSD(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[0] * a.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07482573425339499"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSD(graph_predicted,graph_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Nov 10 2023, 13:38:27) \n[Clang 15.0.0 (clang-1500.1.0.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
